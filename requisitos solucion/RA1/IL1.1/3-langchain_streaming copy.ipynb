{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hfn0f7nyumn",
   "metadata": {},
   "source": [
    "# 3. LangChain Streaming - Respuestas en Tiempo Real\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender qu√© es el streaming y cu√°ndo usarlo\n",
    "- Implementar streaming con LangChain\n",
    "- Manejar chunks de datos en tiempo real\n",
    "- Construir interfaces de usuario reactivas\n",
    "\n",
    "## ¬øQu√© es el Streaming?\n",
    "\n",
    "El streaming permite recibir la respuesta del modelo **token por token** conforme se genera, en lugar de esperar a que termine completamente. Esto mejora significativamente la experiencia de usuario en aplicaciones interactivas.\n",
    "\n",
    "### Ventajas del Streaming:\n",
    "- **Percepci√≥n de velocidad**: El usuario ve progreso inmediato\n",
    "- **Mejor UX**: Interfaces m√°s reactivas e interactivas  \n",
    "- **Engagement**: Mantiene la atenci√≥n del usuario\n",
    "- **Debugging**: Permite ver el proceso de generaci√≥n\n",
    "\n",
    "### Casos de Uso Ideales:\n",
    "- Chatbots y asistentes conversacionales\n",
    "- Generaci√≥n de contenido largo\n",
    "- Aplicaciones web interactivas\n",
    "- Demostraciones en vivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa694f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas correctamente para streaming\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Bibliotecas importadas correctamente para streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f037cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Modelo configurado con streaming habilitado\n",
      "Modelo: openai/gpt-4o-mini\n",
      "Streaming: True\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del modelo con streaming habilitado\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "        model = \"openai/gpt-4o-mini\",               \n",
    "        temperature=0.7,\n",
    "        streaming=True  # Sin streaming\n",
    "       \n",
    "    )\n",
    "    # llm = ChatOpenAI(\n",
    "    #      base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    #      api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "    #      model=\"gpt-4o\",\n",
    "    #      streaming=True,  # ¬°Importante: habilitar streaming!\n",
    "    #      temperature=0.7\n",
    "    #  )\n",
    "    # llm = ChatOpenAI(\n",
    "    #     base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "    #     api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "    #     model = \"openai/gpt-4.1\",               # modelo DeepSeek\n",
    "    #     temperature=0.7,\n",
    "    #     streaming=True, \n",
    "    #     max_tokens=150\n",
    "    # )\n",
    "    \n",
    "    print(\"‚úì Modelo configurado con streaming habilitado\")\n",
    "    print(f\"Modelo: {llm.model_name}\")\n",
    "    print(f\"Streaming: {llm.streaming}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error en configuraci√≥n: {e}\")\n",
    "    print(\"Verifica las variables de entorno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da0d27",
   "metadata": {},
   "source": [
    "## Streaming B√°sico\n",
    "\n",
    "El m√©todo `.stream()` devuelve un generador que produce chunks de texto conforme se generan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f31f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING EN TIEMPO REAL ===\n",
      "Generando respuesta...\n",
      "--------------------------------------------------\n",
      "Hab√≠a una vez en un peque√±o pueblo llamado Herbalia, donde los habitantes eran conocidos por su amor a las plantas y las especias. En el centro del pueblo, hab√≠a una hermosa huerta que siempre estaba llena de aromas y colores. Entre todas las hierbas que all√≠ crec√≠an, el or√©gano era la estrella. \n",
      "\n",
      "Do√±a Clara, la sabia herbolaria del pueblo, siempre dec√≠a: ‚ÄúEl or√©gano no solo da sabor a nuestros platillos, sino que tambi√©n trae consigo muchos beneficios‚Äù. Un d√≠a, un grupo de ni√±os curiosos se acerc√≥ a ella y le pregunt√≥ qu√© hac√≠a tan especial a esta hierba.\n",
      "\n",
      "Do√±a Clara sonri√≥ y comenz√≥ a contarles sobre las maravillas del or√©gano. ‚ÄúPrimero‚Äù, dijo, ‚Äúes un gran aliado para nuestra salud. Tiene propiedades antioxidantes que ayudan a combatir los radicales libres y a mantener nuestro cuerpo joven y fuerte. Adem√°s, es un excelente antiinflamatorio, perfecto para aliviar esos peque√±os dolores que todos sentimos de vez en cuando‚Äù.\n",
      "\n",
      "Los ni√±os escuchaban fascinados mientras Do√±a Clara continuaba: ‚ÄúPero eso no es todo. El or√©gano tambi√©n es un gran amigo del sistema digestivo. Si te sientes un poco mal despu√©s de comer, una infusi√≥n de or√©gano puede ayudarte a sentirte mejor. Y en la cocina, su sabor realza cualquier plato, desde una simple salsa de tomate hasta una deliciosa pizza‚Äù.\n",
      "\n",
      "Intrigados, los ni√±os decidieron ayudar a Do√±a Clara a cosechar un poco de or√©gano. Mientras trabajaban juntos, ella les ense√±√≥ a preparar una infusi√≥n y a usarlo en sus comidas. Pronto, todos en el pueblo comenzaron a notar los beneficios del or√©gano en su salud y en sus recetas.\n",
      "\n",
      "Con el tiempo, Herbalia se convirti√≥ en un lugar famoso no solo por su encantadora huerta, sino tambi√©n por la sabidur√≠a de sus habitantes en el uso de las plantas. Y as√≠, los ni√±os aprendieron que, aunque el or√©gano era una simple hierba, ten√≠a el poder de unir a la comunidad y mejorar la vida de todos.\n",
      "\n",
      "Desde entonces, el or√©gano se convirti√≥ en un s√≠mbolo de salud y bienestar en Herbalia, y la historia de sus beneficios se transmiti√≥ de generaci√≥n en generaci√≥n, recordando a todos que a veces las soluciones m√°s sencillas provienen de la naturaleza misma. Fin.\n",
      "--------------------------------------------------\n",
      "‚úì Streaming completado\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo b√°sico de streaming\n",
    "def streaming_basico():\n",
    "    prompt = \"Cu√©ntame una historia breve sobre los beneficios de el oregano \"\n",
    "    \n",
    "    print(\"=== STREAMING EN TIEMPO REAL ===\")\n",
    "    print(\"Generando respuesta...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # stream() devuelve un generador de chunks\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Imprimir cada chunk sin nueva l√≠nea\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.01)  # Peque√±a pausa para simular streaming visual\n",
    "            \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"‚úì Streaming completado\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error en streaming: {e}\")\n",
    "\n",
    "# Ejecutar streaming b√°sico\n",
    "streaming_basico()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10285d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1A: SPINNER SIMPLE ===\n",
      "Generando respuesta...\n",
      "\n",
      "‚úì Completado!   l or√©gano aporta beneficios antioxidantes, antimicrobianos y antiinflamatorios. Mejora la digesti√≥n, refuerza el sistema inmunol√≥gico, combate infecciones y contribuye a la salud respiratoria. Sus compuestos ayudan a prevenir enfermedades y promueven el bienestar general.\n",
      "\n",
      "Respuesta completa:\n",
      "El or√©gano aporta beneficios antioxidantes, antimicrobianos y antiinflamatorios. Mejora la digesti√≥n, refuerza el sistema inmunol√≥gico, combate infecciones y contribuye a la salud respiratoria. Sus compuestos ayudan a prevenir enfermedades y promueven el bienestar general.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "import re\n",
    "from itertools import cycle\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EJERCICIO 1: INDICADORES DE PROGRESO\n",
    "# =============================================================================\n",
    "\n",
    "def ejercicio1_spinner_simple():\n",
    "    \"\"\"Spinner b√°sico que rota mientras llegan chunks\"\"\"\n",
    "  \n",
    "    spinner = cycle(['|', '/', '-', '\\\\'])\n",
    "    prompt = \"rwsumido en 30 palabras :Explica los beneficios del oregano para la salud\"\n",
    "    \n",
    "    print(\"=== EJERCICIO 1A: SPINNER SIMPLE ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    \n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        \n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Mostrar spinner\n",
    "            sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            \n",
    "        # Limpiar spinner y mostrar resultado\n",
    "        sys.stdout.write('\\r‚úì Completado!   \\n')\n",
    "        print(f\"\\nRespuesta completa:\\n{response_text}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "ejercicio1_spinner_simple()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8852d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1A: SPINNER SIMPLE ===\n",
      "Generando respuesta...\n",
      "\n",
      "                    √©gano ofrece propiedades antioxidantes, antiinflamatorias y antimicrobianas. Favorece la digesti√≥n, fortalece el sistema inmunol√≥gico, protege contra infecciones y contribuye a la salud cardiovascular, gracias a sus compuestos como carvacrol y timol.\n",
      "‚úì Completado!\n",
      "\n",
      "Respuesta completa:\n",
      "El or√©gano ofrece propiedades antioxidantes, antiinflamatorias y antimicrobianas. Favorece la digesti√≥n, fortalece el sistema inmunol√≥gico, protege contra infecciones y contribuye a la salud cardiovascular, gracias a sus compuestos como carvacrol y timol.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#modificado \n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "from itertools import cycle\n",
    "\n",
    "def spinner_task(stop_event):\n",
    "    spinner = cycle(['|', '/', '-', '\\\\'])\n",
    "    while not stop_event.is_set():\n",
    "        sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.1)\n",
    "    sys.stdout.write('\\r' + ' ' * 20 + '\\r')  # limpia la l√≠nea del spinner\n",
    "\n",
    "def ejercicio1_spinner_simple():\n",
    "    prompt = \"resumen en 30 palabras :Explica los beneficios del oregano para la salud\"\n",
    "    print(\"=== EJERCICIO 1A: SPINNER SIMPLE ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    response_text = \"\"\n",
    "    stop_event = threading.Event()\n",
    "    spinner_thread = threading.Thread(target=spinner_task, args=(stop_event,))\n",
    "    spinner_thread.start()\n",
    "\n",
    "    try:\n",
    "        # Recibe e imprime chunks normalmente (sin spinner aqu√≠)\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "        stop_event.set()\n",
    "        spinner_thread.join()\n",
    "        print(\"\\n‚úì Completado!\")\n",
    "        print(f\"\\nRespuesta completa:\\n{response_text}\\n\")\n",
    "    except Exception as e:\n",
    "        stop_event.set()\n",
    "        spinner_thread.join()\n",
    "        print(f\"\\nError: {e}\")\n",
    "\n",
    "ejercicio1_spinner_simple()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2190b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1B: BARRA DE PROGRESO ===\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% (117 chars)\n",
      "\n",
      "\n",
      "Respuesta final:\n",
      "La fotos√≠ntesis es el proceso donde las plantas convierten luz solar, agua y di√≥xido de carbono en glucosa y ox√≠geno.\n",
      "\n",
      "‚úÖ Barra de progreso completada!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def ejercicio1_barra_progreso():\n",
    "    \"\"\"Barra de progreso visual basada en longitud de texto generado\"\"\"\n",
    "    \n",
    "    prompt = \"resume en 20 palabras:Describe el proceso de fotos√≠ntesis en las plantas\"\n",
    "    print(\"=== EJERCICIO 1B: BARRA DE PROGRESO ===\")\n",
    "    \n",
    "    response_text = \"\"\n",
    "    last_percent = 0\n",
    "    bar_length = 30\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Progreso estimado basado en cantidad de caracteres\n",
    "            total_estimate = 30  # puedes ajustar seg√∫n lo largo que esperas que sea la respuesta\n",
    "            progress = min(len(response_text) / total_estimate, 1.0)\n",
    "            \n",
    "            filled_length = int(bar_length * progress)\n",
    "            bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)\n",
    "            percent = int(progress * 100)\n",
    "            \n",
    "            # Solo actualizar si hay un cambio real en porcentaje\n",
    "            if percent != last_percent:\n",
    "                sys.stdout.write(f'\\r[{bar}] {percent}% ({len(response_text)} chars)')\n",
    "                sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "            \n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        # Completa la barra al final\n",
    "        sys.stdout.write('\\r[' + '‚ñà'*bar_length + '] 100% (' + str(len(response_text)) + ' chars)\\n')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        print(f\"\\n\\nRespuesta final:\\n{response_text}\\n\")\n",
    "        print(\"‚úÖ Barra de progreso completada!\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "\n",
    "ejercicio1_barra_progreso()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6214408",
   "metadata": {},
   "source": [
    "## Comparaci√≥n: Streaming vs No-Streaming\n",
    "\n",
    "Veamos la diferencia en experiencia de usuario entre ambos enfoques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8e5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACI√ìN: STREAMING vs NO-STREAMING ===\\n\n",
      "1. SIN STREAMING:\n",
      "--------------------\n",
      "Esperando respuesta completa...\n",
      "\\n[Respuesta recibida despu√©s de 2.90 segundos]\n",
      "El or√©gano es una hierba arom√°tica que ofrece m√∫ltiples beneficios para la salud. Su alto contenido de antioxidantes ayuda a combatir el estr√©s oxidativo, protegiendo las c√©lulas del da√±o. Adem√°s, posee propiedades antimicrobianas que pueden contribuir a la lucha contra infecciones bacterianas y f√∫ngicas. El or√©gano es rico en compuestos antiinflamatorios, lo que puede aliviar s√≠ntomas de enfermedades inflamatorias y mejorar la salud digestiva al estimular la producci√≥n de jugos g√°stricos. Tambi√©n se le atribuyen efectos beneficiosos en la salud respiratoria, al actuar como expectorante natural. Su uso en la cocina no solo realza el sabor de los platillos, sino que tambi√©n promueve una alimentaci√≥n m√°s saludable. En resumen, el or√©gano es una valiosa adici√≥n tanto en la gastronom√≠a como en la medicina natural, ofreciendo propiedades que favorecen el bienestar general.\n",
      "\\n============================================================\\n\n",
      "2. CON STREAMING:\n",
      "------------------\n",
      "Respuesta en tiempo real:\n",
      "El or√©gano es una hierba arom√°tica que ofrece m√∫ltiples beneficios para la salud. Su riqueza en antioxidantes ayuda a combatir el da√±o celular y a fortalecer el sistema inmunol√≥gico. Adem√°s, contiene compuestos antimicrobianos que pueden combatir bacterias y hongos, promoviendo una mejor salud digestiva. El or√©gano tambi√©n es conocido por sus propiedades antiinflamatorias, lo que puede aliviar dolores y reducir la inflamaci√≥n en el cuerpo. Su consumo se asocia con la mejora de la salud respiratoria, aliviando s√≠ntomas de resfriados y alergias. Asimismo, su perfil nutricional incluye vitaminas y minerales esenciales, como vitamina K y manganeso, que son importantes para el metabolismo y la salud √≥sea. Incorporar or√©gano en la dieta no solo enriquece los platos con su sabor distintivo, sino que tambi√©n proporciona una serie de beneficios que contribuyen al bienestar general.\\n\\n[Streaming completado en 6.47 segundos]\n",
      "\\n============================================================\n",
      "OBSERVACIONES:\n",
      "- Sin streaming: El usuario espera sin feedback\n",
      "- Con streaming: El usuario ve progreso inmediato\n",
      "- Mejor percepci√≥n de velocidad con streaming\n",
      "- Streaming es especial para respuestas largas\n"
     ]
    }
   ],
   "source": [
    "# Comparaci√≥n entre streaming y no-streaming\n",
    "def comparar_streaming():\n",
    "\n",
    "    # Modelo sin streaming\n",
    "    llm_no_stream = ChatOpenAI(\n",
    "        base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "        model = \"openai/gpt-4o-mini\",               \n",
    "        temperature=0.7,\n",
    "        streaming=False  # Sin streaming\n",
    "       \n",
    "    )\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "        model = \"openai/gpt-4o-mini\",               \n",
    "        temperature=0.7,\n",
    "        streaming=False  # Sin streaming\n",
    "       \n",
    "    )\n",
    "    \n",
    "    prompt = \"resumido en 150 palabras :Escribe un p√°rrafo sobre beneficions del oregano\"\n",
    "    \n",
    "    print(\"=== COMPARACI√ìN: STREAMING vs NO-STREAMING ===\\\\n\")\n",
    "    \n",
    "    # 1. Sin streaming\n",
    "    print(\"1. SIN STREAMING:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Esperando respuesta completa...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = llm_no_stream.invoke([HumanMessage(content=prompt)])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\\\n[Respuesta recibida despu√©s de {end_time - start_time:.2f} segundos]\")\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60 + \"\\\\n\")\n",
    "    \n",
    "    # 2. Con streaming\n",
    "    print(\"2. CON STREAMING:\")\n",
    "    print(\"-\" * 18)\n",
    "    print(\"Respuesta en tiempo real:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.03)  # Simular pausa para efecto visual\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\\\n\\\\n[Streaming completado en {end_time - start_time:.2f} segundos]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"OBSERVACIONES:\")\n",
    "    print(\"- Sin streaming: El usuario espera sin feedback\")\n",
    "    print(\"- Con streaming: El usuario ve progreso inmediato\")\n",
    "    print(\"- Mejor percepci√≥n de velocidad con streaming\")\n",
    "    print(\"- Streaming es especial para respuestas largas\")\n",
    "\n",
    "# Ejecutar comparaci√≥n\n",
    "comparar_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ad79d",
   "metadata": {},
   "source": [
    "## Implementaci√≥n de un Chatbot Simple con Streaming\n",
    "\n",
    "Creemos un chatbot b√°sico que demuestre el streaming en un contexto pr√°ctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a03cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHATBOT CON STREAMING ===\n",
      "Escribe 'salir' para terminar la conversaci√≥n\\n\n"
     ]
    }
   ],
   "source": [
    "# Chatbot simple con streaming\n",
    "def chatbot_streaming():\n",
    "    print(\"=== CHATBOT CON STREAMING ===\")\n",
    "    print(\"Escribe 'salir' para terminar la conversaci√≥n\\\\n\")\n",
    "    \n",
    "    # Configurar asistente con personalidad\n",
    "    system_message = \"\"\"Eres un asistente √∫til y amigable especializado en tecnolog√≠a. \n",
    "    Respondes de manera clara y concisa, y siempre intentas ser educativo.\"\"\"\n",
    "    \n",
    "    while True:\n",
    "        # Obtener input del usuario\n",
    "        user_input = input(\"\\\\nüßë T√∫: \")\n",
    "        \n",
    "        if user_input.lower() in ['salir', 'exit', 'quit']:\n",
    "            print(\"\\\\nüëã ¬°Hasta luego!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input.strip():\n",
    "            continue\n",
    "            \n",
    "        print(\"\\\\nü§ñ Asistente: \", end=\"\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Streaming de la respuesta\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "            \n",
    "            # Convertir a formato LangChain\n",
    "            from langchain.schema import SystemMessage\n",
    "            lc_messages = [\n",
    "                SystemMessage(content=system_message),\n",
    "                HumanMessage(content=user_input)\n",
    "            ]\n",
    "            \n",
    "            full_response = \"\"\n",
    "            for chunk in llm.stream(lc_messages):\n",
    "                content = chunk.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "                time.sleep(0.02)\n",
    "                \n",
    "            print()  # Nueva l√≠nea al final\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\\\n\\\\n‚è∏Ô∏è Interrumpido por el usuario\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n‚ùå Error: {e}\")\n",
    "            \n",
    "    print(\"\\\\n¬°Gracias por usar el chatbot!\")\n",
    "\n",
    "# Ejecutar chatbot (¬°Pru√©balo!)\n",
    "chatbot_streaming() \n",
    " # Descomenta esta l√≠nea para ejecutar\n",
    "\n",
    "print(\"üí° Descomenta la l√≠nea anterior para probar el chatbot interactivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060e43c",
   "metadata": {},
   "source": [
    "## Streaming Avanzado con Manejo de Chunks\n",
    "\n",
    "Podemos procesar cada chunk individualmente para crear experiencias m√°s sofisticadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86fa1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING AVANZADO CON AN√ÅLISIS ===\n",
      "Analizando chunks conforme llegan...\n",
      "\n",
      "La inteligencia artificial (IA) es\\n[Progreso: 10 chunks, ~8 palabras]\\n\n",
      " una rama de la inform√°tica que busca crear sistemas capaces\\n[Progreso: 20 chunks, ~18 palabras]\\n\n",
      " de realizar tareas que requieren inteligencia humana. El machine\\n[Progreso: 30 chunks, ~28 palabras]\\n\n",
      " learning, una subdisciplina de la IA,\\n[Progreso: 40 chunks, ~38 palabras]\\n\n",
      " funciona mediante algoritmos que permiten a las m√°quinas aprender\\n[Progreso: 50 chunks, ~48 palabras]\\n\n",
      " de datos y mejorar su rendimiento en tareas espec√≠ficas sin\\n[Progreso: 60 chunks, ~58 palabras]\\n\n",
      " ser programadas expl√≠citamente.\\n\\n=== ESTAD√çSTICAS FINALES ===\n",
      "Total de chunks: 66\n",
      "Palabras aproximadas: 63\n",
      "Caracteres totales: 355\n",
      "Promedio chars/chunk: 5.4\n"
     ]
    }
   ],
   "source": [
    "# Streaming con an√°lisis de chunks\n",
    "def streaming_avanzado():\n",
    "    prompt = \" en 50 palabras Explica qu√© es la inteligencia artificial y c√≥mo funciona el machine learning\"\n",
    "    \n",
    "    print(\"=== STREAMING AVANZADO CON AN√ÅLISIS ===\")\n",
    "    print(\"Analizando chunks conforme llegan...\\n\")\n",
    "    \n",
    "    # Variables para estad√≠sticas\n",
    "    chunk_count = 0\n",
    "    total_content = \"\"\n",
    "    words_processed = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            chunk_count += 1\n",
    "            content = chunk.content\n",
    "            total_content += content\n",
    "            \n",
    "            # Contar palabras aproximadas\n",
    "            if content.strip():\n",
    "                words_in_chunk = len(content.split())\n",
    "                words_processed += words_in_chunk\n",
    "            \n",
    "            # Mostrar progreso cada 10 chunks\n",
    "            if chunk_count % 10 == 0:\n",
    "                print(f\"\\\\n[Progreso: {chunk_count} chunks, ~{words_processed} palabras]\\\\n\")\n",
    "            \n",
    "            # Imprimir el contenido\n",
    "            print(content, end=\"\", flush=True)\n",
    "            time.sleep(0.02)  # Pausa ligeramente m√°s larga para ver el an√°lisis\n",
    "        \n",
    "        # Estad√≠sticas finales\n",
    "        print(f\"\\\\n\\\\n=== ESTAD√çSTICAS FINALES ===\")\n",
    "        print(f\"Total de chunks: {chunk_count}\")\n",
    "        print(f\"Palabras aproximadas: {words_processed}\")\n",
    "        print(f\"Caracteres totales: {len(total_content)}\")\n",
    "        print(f\"Promedio chars/chunk: {len(total_content)/chunk_count if chunk_count > 0 else 0:.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\n‚úó Error: {e}\")\n",
    "\n",
    "# Ejecutar streaming avanzado\n",
    "streaming_avanzado()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac251a9d",
   "metadata": {},
   "source": [
    "## Consideraciones T√©cnicas del Streaming\n",
    "\n",
    "### Cu√°ndo Usar Streaming:\n",
    "‚úÖ **S√ç usar streaming:**\n",
    "- Respuestas largas (>100 tokens)\n",
    "- Aplicaciones interactivas\n",
    "- Chatbots y asistentes\n",
    "- Demostraciones en vivo\n",
    "- Cuando la UX es prioritaria\n",
    "\n",
    "‚ùå **NO usar streaming:**\n",
    "- Respuestas muy cortas\n",
    "- Procesamiento batch\n",
    "- APIs de backend sin interfaz\n",
    "- Cuando necesitas la respuesta completa antes de procesar\n",
    "\n",
    "### Mejores Pr√°cticas:\n",
    "1. **Manejo de errores**: Siempre incluye try/catch\n",
    "2. **Indicadores visuales**: Muestra progreso al usuario\n",
    "3. **Cancelaci√≥n**: Permite al usuario interrumpir\n",
    "4. **Buffer management**: Para interfaces web, considera buffering\n",
    "5. **Performance**: Monitorea el uso de recursos\n",
    "\n",
    "## Ejercicios Pr√°cticos\n",
    "\n",
    "### Ejercicio 1: Indicador de Progreso\n",
    "Modifica el c√≥digo para mostrar un indicador de progreso (spinner, barra, porcentaje).\n",
    "\n",
    "### Ejercicio 2: Streaming con Filtros\n",
    "Implementa streaming que filtre o procese chunks espec√≠ficos (ej: resaltar palabras clave).\n",
    "\n",
    "### Ejercicio 3: Chatbot Mejorado\n",
    "Extiende el chatbot con:\n",
    "- Historial de conversaci√≥n\n",
    "- Comandos especiales (/help, /clear)\n",
    "- Diferentes personalidades\n",
    "\n",
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Streaming** mejora la percepci√≥n de velocidad\n",
    "2. **Chunks** se procesan individualmente en tiempo real\n",
    "3. **UX** es significativamente mejor con streaming\n",
    "4. **Implementaci√≥n** requiere manejo cuidadoso de generadores\n",
    "5. **Casos de uso** espec√≠ficos donde streaming aporta valor\n",
    "\n",
    "## Pr√≥ximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos la **memoria en LangChain**, que nos permite mantener contexto entre m√∫ltiples interacciones del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced2c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando respuesta...\n",
      "‚úÖ Completado!        \n",
      "\n",
      "**Python** es un **lenguaje de programaci√≥n** de alto nivel, interpretado, multiparadigma (soporta programaci√≥n orientada a objetos, imperativa y funcional), y de prop√≥sito general. Fue creado por **Guido van Rossum** y publicado en 1991. Su dise√±o enfatiza la legibilidad del c√≥digo y una sintaxis sencilla que permite a los programadores expresar conceptos en menos l√≠neas de c√≥digo que otros lenguajes.\n",
      "\n",
      "### Ventajas de Python\n",
      "\n",
      "1. **Sintaxis sencilla y legible**  \n",
      "   Python est√° dise√±ado para ser f√°cil de leer y escribir, lo que facilita el aprendizaje y el desarrollo r√°pido.\n",
      "\n",
      "2. **Gran comunidad y soporte**  \n",
      "   Cuenta con una comunidad activa que aporta miles de librer√≠as\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#import time\n",
    "from itertools import cycle\n",
    "#from langchain_openai import ChatOpenAI\n",
    "#from langchain.schema import HumanMessage\n",
    "\n",
    "def spinner_progreso():\n",
    "    \"\"\"Spinner que rota mientras llegan los chunks\"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Caracteres del spinner\n",
    "    spinner = cycle(['‚†ã', '‚†ô', '‚†π', '‚†∏', '‚†º', '‚†¥', '‚†¶', '‚†ß', '‚†á', '‚†è'])\n",
    "    \n",
    "    prompt = \"Explica qu√© es Python y sus ventajas\"\n",
    "    response_text = \"\"\n",
    "    \n",
    "    print(\"Generando respuesta...\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Mostrar spinner\n",
    "            sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        # Limpiar spinner y mostrar resultado\n",
    "        sys.stdout.write('\\r‚úÖ Completado!        \\n\\n')\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "spinner_progreso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b67c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Barra de Progreso ===\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% (617 chars)\n",
      "\n",
      "Respuesta completa:\n",
      "Claro, aqu√≠ tienes una descripci√≥n paso a paso del proceso de **machine learning** (aprendizaje autom√°tico):\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Definici√≥n del problema**\n",
      "   - Identifica y comprende el problema que deseas resolver.\n",
      "   - Ejemplo: ¬øQuieres clasificar correos como spam/no spam?\n",
      "\n",
      "### 2. **Recolecci√≥n de datos**\n",
      "   - Obt√©n datos relevantes para el problema.\n",
      "   - Pueden provenir de bases de datos, sensores, web, etc.\n",
      "\n",
      "### 3. **Preprocesamiento de datos**\n",
      "   - Limpieza: Elimina duplicados, corrige errores y trata valores faltantes.\n",
      "   - Transformaci√≥n: Normaliza o estandariza datos, convierte variables categ√≥ricas en num\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "def barra_progreso():\n",
    "    \"\"\"Barra de progreso basada en caracteres generados\"\"\"\n",
    "    \n",
    "    prompt = \"Describe el proceso de machine learning paso a paso\"\n",
    "    response_text = \"\"\n",
    "    bar_length = 25\n",
    "    estimated_total = 400  # Estimaci√≥n de caracteres esperados\n",
    "    \n",
    "    print(\"=== Barra de Progreso ===\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Calcular progreso\n",
    "            progress = min(len(response_text) / estimated_total, 1.0)\n",
    "            filled = int(bar_length * progress)\n",
    "            \n",
    "            # Crear barra visual\n",
    "            bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)\n",
    "            percent = int(progress * 100)\n",
    "            \n",
    "            # Actualizar barra\n",
    "            sys.stdout.write(f'\\r[{bar}] {percent}% ({len(response_text)} chars)')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        # Completar al 100%\n",
    "        sys.stdout.write(f'\\r[{\"‚ñà\" * bar_length}] 100% ({len(response_text)} chars)\\n\\n')\n",
    "        print(\"Respuesta completa:\")\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "barra_progreso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6143ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Contador de Palabras ===\n",
      "Generando respuesta...\n",
      "\n",
      "üìù Palabras: 103 | Caracteres: 727\n",
      "\n",
      "‚úÖ Generaci√≥n completada!\n",
      "üìä Estad√≠sticas finales: 103 palabras, 727 caracteres\n",
      "\n",
      "Respuesta:\n",
      "La inteligencia artificial (IA) ofrece numerosos beneficios en diferentes √°mbitos de la vida y sectores productivos. Algunos de los principales son:\n",
      "\n",
      "1. **Automatizaci√≥n de tareas**: Permite que procesos repetitivos o complejos se realicen de forma autom√°tica, ahorrando tiempo y reduciendo errores humanos.\n",
      "\n",
      "2. **Mejora en la toma de decisiones**: La IA puede analizar grandes cantidades de datos y ofrecer recomendaciones o predicciones m√°s precisas que las realizadas manualmente.\n",
      "\n",
      "3. **Personalizaci√≥n**: En √°reas como el comercio electr√≥nico, la educaci√≥n y la salud, la IA puede adaptar productos, servicios o contenidos a las necesidades y preferencias individuales de los usuarios.\n",
      "\n",
      "4. **Eficiencia operativa**: Ayuda a\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def contador_palabras():\n",
    "    \"\"\"Muestra el conteo de palabras conforme se genera el texto\"\"\"\n",
    "    \n",
    "    prompt = \"Cu√©ntame sobre los beneficios de la inteligencia artificial\"\n",
    "    response_text = \"\"\n",
    "    \n",
    "    print(\"=== Contador de Palabras ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Contar palabras\n",
    "            words = len(re.findall(r'\\b\\w+\\b', response_text))\n",
    "            chars = len(response_text)\n",
    "            \n",
    "            # Mostrar progreso\n",
    "            sys.stdout.write(f'\\rüìù Palabras: {words} | Caracteres: {chars}')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(f\"\\n\\n‚úÖ Generaci√≥n completada!\")\n",
    "        print(f\"üìä Estad√≠sticas finales: {words} palabras, {chars} caracteres\\n\")\n",
    "        print(\"Respuesta:\")\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "contador_palabras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4604485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING CON RESALTADO DE PALABRAS CLAVE ===\n",
      "üîç Palabras clave: python, machine learning, inteligencia artificial, algoritmo, datos, modelo\n",
      "\n",
      "Respuesta (palabras clave resaltadas con *):\n",
      "--------------------------------------------------\n",
      "***PYTHON*** es un lenguaje de programaci√≥n de alto nivel, de prop√≥sito general, que se caracteriza por ser sencillo, legible y f√°cil de aprender. Fue creado a finales de los a√±os 80 y desde entonces ha ganado enorme popularidad, especialmente en √°reas como ciencia de *DATOS*, desarrollo web, automatizaci√≥n y, de manera destacada, en **machine learning (aprendizaje autom√°tico)** e **inteligencia artificial (IA)**.\n",
      "\n",
      "### ¬øQu√© es *PYTHON*?\n",
      "\n",
      "- **Sintaxis clara y sencilla**, lo que facilita el desarrollo y mantenimiento de c√≥digo.\n",
      "- Es **multiparadigma**, permitiendo programaci√≥n orientada a objetos, imperativa y funcional.\n",
      "- Posee una **gran comunidad** y una **amplia colecci√≥n de bibliotecas\n",
      "--------------------------------------------------\n",
      "‚úÖ Streaming completado!\n",
      "üéØ Palabras clave resaltadas: 3\n"
     ]
    }
   ],
   "source": [
    "def streaming_con_resaltado():\n",
    "    \"\"\"Resalta palabras clave espec√≠ficas durante el streaming\"\"\"\n",
    "    \n",
    "    # Palabras clave a resaltar\n",
    "    keywords = [\"python\", \"machine learning\", \"inteligencia artificial\", \"algoritmo\", \"datos\", \"modelo\"]\n",
    "    \n",
    "    prompt = \"Explica qu√© es Python y c√≥mo se usa en machine learning e inteligencia artificial\"\n",
    "    \n",
    "    print(\"=== STREAMING CON RESALTADO DE PALABRAS CLAVE ===\")\n",
    "    print(f\"üîç Palabras clave: {', '.join(keywords)}\\n\")\n",
    "    print(\"Respuesta (palabras clave resaltadas con *):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response_text = \"\"\n",
    "    highlighted_count = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            content = chunk.content\n",
    "            response_text += content\n",
    "            \n",
    "            # Procesar cada chunk para resaltar palabras clave\n",
    "            processed_content = content\n",
    "            for keyword in keywords:\n",
    "                # Buscar la palabra clave (insensible a may√∫sculas/min√∫sculas)\n",
    "                pattern = re.compile(re.escape(keyword), re.IGNORECASE)\n",
    "                if pattern.search(processed_content):\n",
    "                    processed_content = pattern.sub(f\"*{keyword.upper()}*\", processed_content)\n",
    "                    highlighted_count += 1\n",
    "            \n",
    "            # Mostrar el chunk procesado\n",
    "            print(processed_content, end=\"\", flush=True)\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(f\"\\n{'-' * 50}\")\n",
    "        print(f\"‚úÖ Streaming completado!\")\n",
    "        print(f\"üéØ Palabras clave resaltadas: {highlighted_count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "streaming_con_resaltado()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
