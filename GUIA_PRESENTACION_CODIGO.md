# ğŸ¯ GUÃA DE PRESENTACIÃ“N DEL CÃ“DIGO (7 MINUTOS)

## **MINUTO 1: IntroducciÃ³n y Estructura General** â±ï¸ 0:00-1:00

**"Mi cÃ³digo tiene 928 lÃ­neas organizadas en 4 bloques principales:"**

```
1. CONFIGURACIÃ“N Y HERRAMIENTAS (lÃ­neas 1-99)
   â”œâ”€ LangSmith para observabilidad
   â”œâ”€ Logging persistente (logs_agentes.log)
   â””â”€ HerramientaSoporte con 3 funciones:
      â€¢ calculadora_matematica() - cÃ¡lculos de hardware
      â€¢ buscar_informacion() - bÃºsqueda por categorÃ­a
      â€¢ analizar_problema() - clasificaciÃ³n automÃ¡tica

2. SISTEMA DE MEMORIA AVANZADA (lÃ­neas 100-249)
   â””â”€ 5 tipos de memoria LangChain integrados

3. AGENTE ESPECIALIZADO (lÃ­neas 250-449)
   â””â”€ Clase base para los 5 agentes

4. ORQUESTADOR + INTERFAZ STREAMLIT (lÃ­neas 450-928)
   â””â”€ Coordina agentes + UI multipÃ¡gina
```

---

## **MINUTO 2: HerramientaSoporte (RA2)** â±ï¸ 1:00-2:00

**"Implemento 3 herramientas compartidas entre agentes:"**

```python
class HerramientaSoporte:
    # 1. Calculadora para requisitos tÃ©cnicos
    @staticmethod
    def calculadora_matematica(expresion: str):
        # Eval seguro con funciones permitidas
        # Ejemplo: "2*1024" â†’ "2048 MB"
    
    # 2. BÃºsqueda categorizada
    @staticmethod
    def buscar_informacion(query: str, categoria: str):
        # Retorna info por categorÃ­a (hardware/software/etc)
    
    # 3. AnÃ¡lisis automÃ¡tico de consulta
    @staticmethod
    def analizar_problema(descripcion: str):
        # Detecta palabras clave â†’ asigna categorÃ­a + prioridad
        # "mi wifi no funciona" â†’ {"categoria": "redes", "prioridad": "alta"}
```

**Punto clave:** "Estas herramientas son el cerebro de la orquestaciÃ³n, clasifican automÃ¡ticamente las consultas."

---

## **MINUTO 3: Sistema de Memoria (RA1)** â±ï¸ 2:00-3:00

**"Implemento 5 tipos de memoria LangChain para contexto conversacional:"**

```python
class SistemaMemoriaAvanzada:
    def __init__(self, llm, embeddings):
        # 1. Buffer - Historial completo
        self.buffer_memory = ConversationBufferMemory(...)
        
        # 2. Summary - Resumen inteligente
        self.summary_memory = ConversationSummaryMemory(llm=llm)
        
        # 3. Window - Solo Ãºltimas 5 interacciones
        self.window_memory = ConversationBufferWindowMemory(k=5)
        
        # 4. Entity - Recuerda nombres, dispositivos
        self.entity_memory = ConversationEntityMemory(llm=llm)
        
        # 5. Vector - Memoria a largo plazo con FAISS
        self.vector_memory = VectorStoreRetrieverMemory(retriever=...)
```

**Punto clave:** "Cada agente tiene su propio sistema de memoria completo, permitiendo contexto personalizado."

---

## **MINUTO 4: Agente Especializado + RAG FAISS** â±ï¸ 3:00-4:00

**"La clase AgenteEspecializado es el nÃºcleo del sistema:"**

```python
class AgenteEspecializado:
    def __init__(self, nombre, especialidad):
        self.llm = ChatOpenAI(...)  # GPT-4o-mini con GitHub
        self.embeddings = OpenAIEmbeddings(...)
        self.memoria = SistemaMemoriaAvanzada(...)  # 5 tipos
        self.vectorstore_rag = None  # FAISS para RAG
    
    # Carga material de conocimiento con FAISS
    def cargar_material(self, contenido: str):
        chunks = self.text_splitter.split_documents([doc])
        self.vectorstore_rag = FAISS.from_documents(chunks, self.embeddings)
    
    # BÃºsqueda semÃ¡ntica con FAISS
    def buscar_contexto_faiss(self, consulta: str) -> str:
        docs = self.vectorstore_rag.similarity_search(consulta, k=3)
        return "\n\n".join([doc.page_content for doc in docs])
    
    # Procesa consulta con FAISS + Memoria + LLM
    def procesar_consulta(self, consulta: str):
        contexto_faiss = self.buscar_contexto_faiss(consulta)
        contexto_memoria = self.memoria.obtener_contexto_completo()
        # Construye prompt con ambos contextos â†’ streaming
```

**Punto clave:** "Cada agente busca contexto relevante con FAISS antes de responder, combinando RAG + memoria para respuestas personalizadas."

---

## **MINUTO 5: Orquestador Multi-Agente** â±ï¸ 4:00-5:00

**"El OrquestadorMultiagente coordina los 5 agentes:"**

```python
class OrquestadorMultiagente:
    def __init__(self):
        self.agentes = {
            "hardware": AgenteEspecializado("ğŸ”§ Agente Hardware", ...),
            "software": AgenteEspecializado("ğŸ’» Agente Software", ...),
            "redes": AgenteEspecializado("ğŸŒ Agente Redes", ...),
            "seguridad": AgenteEspecializado("ğŸ”’ Agente Seguridad", ...),
            "general": AgenteEspecializado("âš™ï¸ Agente General", ...)
        }
    
    # Proceso principal:
    def procesar_consulta_compleja(self, consulta: str):
        # 1. Analizar problema â†’ categorÃ­a
        analisis = self.herramientas.analizar_problema(consulta)
        
        # 2. Seleccionar agente principal
        agente_principal = self.agentes[analisis["categoria"]]
        
        # 3. Procesar con agente principal
        respuesta = agente_principal.procesar_consulta(consulta)
        
        # 4. Â¿Necesita colaboraciÃ³n?
        if self._necesita_colaboracion(consulta):
            # Obtener input de otros agentes
            agentes_colaboradores = self._obtener_agentes_colaboradores(...)
            # Integrar respuestas
        
        return respuesta_integrada
```

**Punto clave:** "El orquestador analiza, enruta, coordina colaboraciÃ³n y registra todo en logs + mÃ©tricas."

---

## **MINUTO 6: Interfaz Streamlit Multi-PÃ¡gina** â±ï¸ 5:00-6:00

**"La interfaz tiene navegaciÃ³n con 3 pÃ¡ginas:"**

```python
# Streamlit configurado como multipÃ¡gina
st.set_page_config(page_title="Sistema Multi-Agente", layout="wide")

# Sidebar con navegaciÃ³n
pagina = st.sidebar.radio("NavegaciÃ³n", ["ğŸ  Chat", "ğŸ“Š MÃ©tricas", "ğŸ“‹ Logs"])

if pagina == "ğŸ  Chat":
    # Interfaz principal de chat
    # Historial conversacional + streaming
    # Botones para funciones especiales
    
elif pagina == "ğŸ“Š MÃ©tricas":
    # Dashboard con:
    # - MÃ©tricas por agente (consultas, tiempo, resoluciÃ³n)
    # - MÃ©tricas globales (total consultas, colaboraciones)
    # - GrÃ¡ficos Plotly interactivos
    # - MÃ©tricas de LangSmith (traces, latencia)
    
elif pagina == "ğŸ“‹ Logs":
    # Ãšltimos eventos del sistema
    # logs_agentes.log parseado
    # Filtros por nivel (INFO, WARNING, ERROR)
```

**Punto clave:** "Todo estÃ¡ visualizado: el usuario ve chat, mÃ©tricas en tiempo real y logs del sistema."

---

## **MINUTO 7: Flujo Completo + Demo** â±ï¸ 6:00-7:00

**"Flujo end-to-end de una consulta:"**

```
Usuario escribe: "Mi computadora estÃ¡ lenta y no puedo conectarme a WiFi"
    â†“
1. HerramientaSoporte.analizar_problema()
   â†’ Detecta 2 categorÃ­as: hardware + redes
    â†“
2. OrquestadorMultiagente.procesar_consulta_compleja()
   â†’ Selecciona agente principal: Hardware
    â†“
3. AgenteEspecializado.procesar_consulta()
   â”œâ”€ buscar_contexto_faiss("computadora lenta") â†’ contexto RAM/CPU
   â”œâ”€ memoria.obtener_contexto_completo() â†’ historial usuario
   â”œâ”€ Construye prompt con FAISS + memoria
   â””â”€ llm.stream() â†’ respuesta en tiempo real
    â†“
4. Orquestador detecta necesidad colaboraciÃ³n
   â†’ Consulta a Agente Redes sobre WiFi
    â†“
5. Integra ambas respuestas
    â†“
6. Guarda en memoria de ambos agentes
    â†“
7. Registra en logs + actualiza mÃ©tricas + envÃ­a a LangSmith
    â†“
Usuario recibe respuesta completa con soluciÃ³n hardware + redes
```

**Frase de cierre:**
*"928 lÃ­neas que implementan un sistema completo: clasificaciÃ³n automÃ¡tica, 5 agentes con RAG+FAISS, 5 tipos de memoria, orquestaciÃ³n inteligente, colaboraciÃ³n multi-agente y observabilidad total. Todo funcional en Streamlit."*

---

## ğŸ“ **TIPS PARA LA PRESENTACIÃ“N:**

1. **Abre el archivo en VS Code** y seÃ±ala las lÃ­neas mientras explicas
2. **Ten Streamlit corriendo** para mostrar interfaz rÃ¡pidamente
3. **Prepara una demo rÃ¡pida** (30 seg): una consulta compleja en vivo
4. **Enfatiza los nÃºmeros:** 928 lÃ­neas, 5 agentes, 5 memorias, 3 herramientas
5. **Usa tÃ©rminos tÃ©cnicos clave:** FAISS, RAG, streaming, embeddings, orquestaciÃ³n

---

## ğŸ” **REFERENCIAS RÃPIDAS (Si te preguntan por alguna parte especÃ­fica):**

| Componente | LÃ­neas | DescripciÃ³n |
|---|---|---|
| **ConfiguraciÃ³n** | 1-99 | LangSmith, logging, HerramientaSoporte |
| **Memoria** | 100-249 | SistemaMemoriaAvanzada (5 tipos) |
| **RAG FAISS** | 290-320 | cargar_material(), buscar_contexto_faiss() |
| **Agente** | 250-449 | AgenteEspecializado completo |
| **Orquestador** | 450-600 | OrquestadorMultiagente |
| **Streamlit** | 600-928 | UI multipÃ¡gina + dashboard |

---

## ğŸ’¡ **FRASES CLAVE PARA IMPRESIONAR:**

- "Implemento RAG con FAISS para bÃºsqueda semÃ¡ntica en el material de conocimiento"
- "Cada agente tiene 5 tipos de memoria LangChain para contexto enriquecido"
- "El orquestador analiza automÃ¡ticamente la consulta y coordina colaboraciÃ³n multi-agente"
- "Todo observable: LangSmith para traces, logs persistentes y dashboard Streamlit"
- "928 lÃ­neas que integran RA1 (RAG + memoria) y RA2 (agentes + orquestaciÃ³n)"

---

## ğŸ¯ **POSIBLES PREGUNTAS Y RESPUESTAS:**

**P: "Â¿Por quÃ© 5 agentes y no mÃ¡s o menos?"**  
R: "Cubren las categorÃ­as principales de soporte IT: hardware, software, redes, seguridad y general. MÃ¡s agentes aumentarÃ­an complejidad sin mejora significativa en cobertura."

**P: "Â¿CÃ³mo garantizas que el agente correcto responde?"**  
R: "La funciÃ³n `analizar_problema()` usa anÃ¡lisis de palabras clave para clasificar. Si hay ambigÃ¼edad, el orquestador puede activar mÃºltiples agentes en colaboraciÃ³n."

**P: "Â¿Por quÃ© FAISS y no otra base vectorial?"**  
R: "FAISS es rÃ¡pida, local (sin costos API) y suficiente para el tamaÃ±o actual del material. Para producciÃ³n, considerarÃ­a Pinecone o Weaviate."

**P: "Â¿CuÃ¡l es el bottleneck del sistema?"**  
R: "Las llamadas al LLM. Por eso uso streaming para mejor UX. En las propuestas de mejora documento cache multi-nivel para reducir latencia 70%."

---

Â¡Ã‰xito en tu presentaciÃ³n! ğŸš€
