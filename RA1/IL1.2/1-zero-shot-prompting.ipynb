{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Zero-Shot Prompting - Prompts Sin Ejemplos Previos\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender los principios del zero-shot prompting\n",
    "- Diseñar prompts efectivos sin ejemplos previos\n",
    "- Aplicar técnicas de instrucción clara y contexto\n",
    "- Evaluar la efectividad de diferentes enfoques zero-shot\n",
    "\n",
    "## ¿Qué es Zero-Shot Prompting?\n",
    "\n",
    "Zero-shot prompting es la técnica donde pedimos al modelo realizar una tarea **sin proporcionar ejemplos específicos** de cómo debe hacerla. El modelo debe basarse únicamente en:\n",
    "- Su entrenamiento previo\n",
    "- Las instrucciones que le damos\n",
    "- El contexto que proporcionamos\n",
    "\n",
    "### Ventajas:\n",
    "- **Simplicidad**: No requiere crear ejemplos\n",
    "- **Flexibilidad**: Fácil de adaptar a nuevas tareas\n",
    "- **Eficiencia**: Menos tokens utilizados\n",
    "- **Generalización**: Funciona para tareas diversas\n",
    "\n",
    "### Limitaciones:\n",
    "- **Inconsistencia**: Resultados pueden variar más\n",
    "- **Formato**: Menos control sobre la estructura de salida\n",
    "- **Tareas complejas**: Puede requerir instrucciones muy detalladas\n",
    "- **Dominio específico**: Menos efectivo en nichos especializados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Configurar el modelo\n",
    "llm = ChatOpenAI(\n",
    "base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "model = \"openai/gpt-4.1\", \n",
    "    #base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    #api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "    #model=\"gpt-4o\",\n",
    "    temperature=0.7  # Balance entre creatividad y consistencia\n",
    ")\n",
    "\n",
    "print(\"✓ Modelo configurado para zero-shot prompting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomía de un Prompt Zero-Shot Efectivo\n",
    "\n",
    "Un prompt zero-shot efectivo tiene estos componentes:\n",
    "\n",
    "1. **Contexto/Rol**: Quién debe \"ser\" el modelo\n",
    "2. **Tarea**: Qué debe hacer específicamente\n",
    "3. **Formato**: Cómo debe estructurar la respuesta\n",
    "4. **Restricciones**: Qué debe evitar o considerar\n",
    "5. **Input**: Los datos específicos a procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo básico vs mejorado\n",
    "def comparar_prompts_basico():\n",
    "    texto = \"El nuevo iPhone tiene una batería increíble y la cámara es fantástica, pero el precio es muy alto.\"\n",
    "    \n",
    "    # Prompt básico (menos efectivo)\n",
    "    prompt_basico = f\"Analiza este texto: {texto}\"\n",
    "    \n",
    "    # Prompt mejorado (más efectivo)\n",
    "    prompt_mejorado = f\"\"\"Eres un analista de sentimientos experto. \n",
    "    \n",
    "Tarea: Analiza el sentimiento del siguiente texto sobre un producto.\n",
    "    \n",
    "Formato de respuesta:\n",
    "- Sentimiento general: [Positivo/Negativo/Neutral]\n",
    "- Aspectos positivos: [lista]\n",
    "- Aspectos negativos: [lista]\n",
    "- Puntuación de confianza: [0-10]\n",
    "    \n",
    "Texto a analizar: \"{texto}\"\"\"\n",
    "    \n",
    "    print(\"=== COMPARACIÓN DE PROMPTS ===\")\n",
    "    \n",
    "    # Probar prompt básico\n",
    "    print(\"\\n1. PROMPT BÁSICO:\")\n",
    "    print(f\"Prompt: {prompt_basico}\")\n",
    "    try:\n",
    "        response1 = llm.invoke([HumanMessage(content=prompt_basico)])\n",
    "        print(f\"Respuesta: {response1.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    \n",
    "    # Probar prompt mejorado\n",
    "    print(\"\\n2. PROMPT MEJORADO:\")\n",
    "    print(f\"Prompt: {prompt_mejorado[:100]}...\")\n",
    "    try:\n",
    "        response2 = llm.invoke([HumanMessage(content=prompt_mejorado)])\n",
    "        print(f\"Respuesta: {response2.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n=== ANÁLISIS ===\")\n",
    "    print(\"• Prompt básico: Ambiguo, respuesta poco estructurada\")\n",
    "    print(\"• Prompt mejorado: Específico, respuesta estructurada y útil\")\n",
    "\n",
    "# Ejecutar comparación\n",
    "comparar_prompts_basico()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas de Zero-Shot por Tipo de Tarea\n",
    "\n",
    "Diferentes tipos de tareas requieren enfoques específicos en zero-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CLASIFICACIÓN\n",
    "def zero_shot_clasificacion():\n",
    "    print(\"=== ZERO-SHOT PARA CLASIFICACIÓN ===\")\n",
    "    \n",
    "    emails = [\n",
    "        \"Reunión de equipo mañana a las 10 AM en sala de conferencias\",\n",
    "        \"¡Felicidades! Has ganado $1,000,000! Haz clic aquí ahora\",\n",
    "        \"Recordatorio: Tu factura de internet vence en 3 días\"\n",
    "    ]\n",
    "    \n",
    "    # Prompt optimizado para clasificación\n",
    "    clasificacion_prompt = \"\"\"Eres un clasificador de emails empresariales.\n",
    "    \n",
    "Clasifica cada email en una de estas categorías:\n",
    "- TRABAJO: Relacionado con tareas laborales\n",
    "- SPAM: Contenido no solicitado o sospechoso\n",
    "- PERSONAL: Asuntos personales o administrativos\n",
    "\n",
    "Responde solo con el nombre de la categoría.\n",
    "\n",
    "Email: \"{}\"\n",
    "Categoría:\"\"\"\n",
    "    \n",
    "    for i, email in enumerate(emails, 1):\n",
    "        prompt = clasificacion_prompt.format(email)\n",
    "        try:\n",
    "            response = llm.invoke([HumanMessage(content=prompt)])\n",
    "            print(f\"{i}. Email: {email[:50]}...\")\n",
    "            print(f\"   Clasificación: {response.content.strip()}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error en email {i}: {e}\")\n",
    "\n",
    "# Ejecutar clasificación\n",
    "zero_shot_clasificacion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GENERACIÓN DE CONTENIDO\n",
    "def zero_shot_generacion():\n",
    "    print(\"=== ZERO-SHOT PARA GENERACIÓN ===\")\n",
    "    \n",
    "    # Prompt estructurado para generación\n",
    "    generacion_prompt = \"\"\"Eres un copywriter creativo especializado en redes sociales.\n",
    "    \n",
    "Tarea: Crear un post para LinkedIn sobre el tema dado.\n",
    "    \n",
    "Requisitos:\n",
    "- Tono profesional pero accesible\n",
    "- Máximo 150 palabras\n",
    "- Incluir 1-2 hashtags relevantes\n",
    "- Hacer una pregunta para fomentar engagement\n",
    "    \n",
    "Tema: \"Importancia del aprendizaje continuo en tecnología\"\n",
    "    \n",
    "Post para LinkedIn:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=generacion_prompt)])\n",
    "        print(\"Post generado:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(response.content)\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Análisis del resultado\n",
    "        words = len(response.content.split())\n",
    "        hashtags = response.content.count('#')\n",
    "        questions = response.content.count('?')\n",
    "        \n",
    "        print(f\"\\nAnálisis:\")\n",
    "        print(f\"• Palabras: {words} (límite: 150)\")\n",
    "        print(f\"• Hashtags: {hashtags}\")\n",
    "        print(f\"• Preguntas: {questions}\")\n",
    "        print(f\"• Cumple requisitos: {'✓' if words <= 150 and hashtags >= 1 and questions >= 1 else '✗'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar generación\n",
    "zero_shot_generacion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. EXTRACCIÓN DE INFORMACIÓN\n",
    "def zero_shot_extraccion():\n",
    "    print(\"=== ZERO-SHOT PARA EXTRACCIÓN ===\")\n",
    "    \n",
    "    # Texto de ejemplo\n",
    "    texto_noticia = \"\"\"Apple Inc. anunció hoy que su CEO Tim Cook se reunirá con inversores \n",
    "    el próximo 15 de marzo de 2024 en Cupertino, California. La reunión abordará los \n",
    "    resultados financieros del Q1 2024, donde la compañía reportó ingresos de $89.5 \n",
    "    billones. Cook también discutirá la nueva estrategia de IA de Apple y el lanzamiento \n",
    "    del iPhone 16 programado para septiembre. Las acciones de Apple (AAPL) subieron \n",
    "    3.2% tras el anuncio.\"\"\"\n",
    "    \n",
    "    # Prompt para extracción estructurada\n",
    "    extraccion_prompt = f\"\"\"Eres un analista financiero experto en extraer datos clave.\n",
    "    \n",
    "Extrae la siguiente información del texto dado:\n",
    "    \n",
    "Formato de respuesta (JSON):\n",
    "{{\n",
    "  \"empresa\": \"nombre de la empresa\",\n",
    "  \"ceo\": \"nombre del CEO\",\n",
    "  \"fecha_evento\": \"fecha del evento\",\n",
    "  \"ubicacion\": \"ubicación del evento\",\n",
    "  \"ingresos\": \"cifra de ingresos mencionada\",\n",
    "  \"productos\": [\"lista de productos mencionados\"],\n",
    "  \"cambio_acciones\": \"porcentaje de cambio en acciones\"\n",
    "}}\n",
    "    \n",
    "Texto: \"{texto_noticia}\"\n",
    "    \n",
    "JSON:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=extraccion_prompt)])\n",
    "        print(\"Información extraída:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Intentar parsear como JSON para validar formato\n",
    "        import json\n",
    "        try:\n",
    "            data = json.loads(response.content)\n",
    "            print(\"\\n✓ Formato JSON válido\")\n",
    "            print(f\"✓ Campos extraídos: {len(data)} elementos\")\n",
    "        except:\n",
    "            print(\"\\n✗ Formato JSON inválido - necesita refinamiento del prompt\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar extracción\n",
    "zero_shot_extraccion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de Prompts Zero-Shot\n",
    "\n",
    "Técnicas para mejorar la efectividad de prompts zero-shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Técnica 1: Prompts con Roles Específicos\n",
    "def roles_especificos():\n",
    "    print(\"=== OPTIMIZACIÓN: ROLES ESPECÍFICOS ===\")\n",
    "    \n",
    "    pregunta = \"¿Cómo puedo mejorar el rendimiento de mi aplicación web?\"\n",
    "    \n",
    "    roles = {\n",
    "        \"Genérico\": \"Responde la siguiente pregunta:\",\n",
    "        \"Desarrollador Senior\": \"Eres un desarrollador senior con 10 años de experiencia en optimización web. Responde como un experto:\",\n",
    "        \"Consultor de Performance\": \"Eres un consultor especializado en performance web que ha optimizado cientos de aplicaciones. Proporciona una respuesta detallada y técnica:\",\n",
    "        \"CTO\": \"Eres un CTO de una startup tecnológica. Responde con una perspectiva estratégica y técnica balanceada:\"\n",
    "    }\n",
    "    \n",
    "    for rol, contexto in roles.items():\n",
    "        prompt = f\"{contexto}\\n\\n{pregunta}\"\n",
    "        \n",
    "        print(f\"\\n{rol.upper()}:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke([HumanMessage(content=prompt)])\n",
    "            # Mostrar solo las primeras líneas para comparación\n",
    "            preview = response.content[:200] + \"...\" if len(response.content) > 200 else response.content\n",
    "            print(preview)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n=== OBSERVACIONES ===\")\n",
    "    print(\"• Roles específicos generan respuestas más enfocadas\")\n",
    "    print(\"• La experticia del rol influye en la profundidad técnica\")\n",
    "    print(\"• El contexto profesional afecta el tipo de soluciones propuestas\")\n",
    "\n",
    "# Ejecutar ejemplo de roles\n",
    "roles_especificos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Técnica 2: Instrucciones Graduales\n",
    "def instrucciones_graduales():\n",
    "    print(\"=== OPTIMIZACIÓN: INSTRUCCIONES GRADUALES ===\")\n",
    "    \n",
    "    # Problema complejo para demostrar\n",
    "    problema = \"Necesito crear una estrategia de marketing digital para lanzar una nueva app de fitness\"\n",
    "    \n",
    "    # Prompt con instrucciones graduales\n",
    "    prompt_gradual = f\"\"\"Eres un estratega de marketing digital senior.\n",
    "    \n",
    "Problema: {problema}\n",
    "    \n",
    "Desarrolla una estrategia siguiendo este proceso paso a paso:\n",
    "    \n",
    "PASO 1: Análisis inicial\n",
    "- Identifica el público objetivo\n",
    "- Define 3 puntos de valor únicos de la app\n",
    "    \n",
    "PASO 2: Canales de marketing\n",
    "- Selecciona 4-5 canales digitales más efectivos\n",
    "- Justifica cada selección\n",
    "    \n",
    "PASO 3: Estrategia de contenido\n",
    "- Define tipos de contenido para cada canal\n",
    "- Sugiere frecuencia de publicación\n",
    "    \n",
    "PASO 4: Métricas y KPIs\n",
    "- Define 5 métricas clave para medir éxito\n",
    "- Sugiere herramientas de medición\n",
    "    \n",
    "Desarrolla cada paso con detalle:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_gradual)])\n",
    "        print(\"ESTRATEGIA DESARROLLADA:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(response.content)\n",
    "        \n",
    "        # Análisis de estructura\n",
    "        pasos_detectados = response.content.count(\"PASO\")\n",
    "        secciones = [\"análisis\", \"canales\", \"contenido\", \"métricas\"]\n",
    "        secciones_encontradas = sum(1 for seccion in secciones if seccion.lower() in response.content.lower())\n",
    "        \n",
    "        print(\"\\n=== ANÁLISIS DE ESTRUCTURA ===\")\n",
    "        print(f\"• Pasos identificados: {pasos_detectados}/4\")\n",
    "        print(f\"• Secciones cubiertas: {secciones_encontradas}/4\")\n",
    "        print(f\"• Estructura seguida: {'✓' if pasos_detectados >= 3 else '✗'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar instrucciones graduales\n",
    "instrucciones_graduales()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casos de Uso Avanzados\n",
    "\n",
    "Aplicaciones más sofisticadas de zero-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso de uso: Análisis de código\n",
    "def analisis_codigo_zero_shot():\n",
    "    print(\"=== CASO DE USO: ANÁLISIS DE CÓDIGO ===\")\n",
    "    \n",
    "    codigo_ejemplo = '''def process_user_data(users):\n",
    "    result = []\n",
    "    for user in users:\n",
    "        if user[\"age\"] > 18:\n",
    "            result.append({\n",
    "                \"name\": user[\"name\"].upper(),\n",
    "                \"email\": user[\"email\"],\n",
    "                \"status\": \"adult\"\n",
    "            })\n",
    "    return result'''\n",
    "    \n",
    "    prompt_analisis = f\"\"\"Eres un senior code reviewer con experiencia en Python.\n",
    "    \n",
    "Analiza el siguiente código y proporciona:\n",
    "    \n",
    "1. FUNCIONALIDAD:\n",
    "   - ¿Qué hace este código?\n",
    "   - ¿Cuál es su propósito?\n",
    "    \n",
    "2. PROBLEMAS POTENCIALES:\n",
    "   - Errores de lógica\n",
    "   - Vulnerabilidades de seguridad\n",
    "   - Problemas de rendimiento\n",
    "    \n",
    "3. MEJORAS SUGERIDAS:\n",
    "   - Optimizaciones de código\n",
    "   - Mejores prácticas\n",
    "   - Manejo de errores\n",
    "    \n",
    "4. PUNTUACIÓN DE CALIDAD: [1-10]\n",
    "    \n",
    "Código a analizar:\n",
    "```python\n",
    "{codigo_ejemplo}\n",
    "```\n",
    "    \n",
    "Análisis:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_analisis)])\n",
    "        print(\"ANÁLISIS DE CÓDIGO:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar análisis de código\n",
    "analisis_codigo_zero_shot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CASO DE USO: GENERACIÓN DE TESTS ===\n",
      "TESTS GENERADOS:\n",
      "==================================================\n",
      "```python\n",
      "import pytest\n",
      "from math import isclose\n",
      "\n",
      "# Suponemos que la función está en el mismo archivo, si está en otro importar\n",
      "from your_module import calculate_discount  # Cambia 'your_module' si es necesario\n",
      "\n",
      "# 1. Casos normales: diferentes tipos de usuario y descuentos\n",
      "@pytest.mark.parametrize(\n",
      "    \"price, discount_percent, user_type, expected\",\n",
      "    [\n",
      "        (100.0, 10, 'regular', 90.0),      # regular, 10% desc\n",
      "        (200.0, 20, 'premium', 150.0),     # premium, 25% desc\n",
      "        (50.0, 0, 'regular', 50.0),        # regular, 0% desc\n",
      "        (80.0, 0, 'premium', 76.0),        # premium, 5% desc extra\n",
      "        (150.0, 100, 'regular', 0.0),      # regular, 100% desc\n",
      "        (150.0, 95, 'premium', 0.0),       # premium, 100% desc (95+5)\n",
      "    ]\n",
      ")\n",
      "def test_calculate_discount_normal(price, discount_percent, user_type, expected):\n",
      "    result = calculate_discount(price, discount_percent, user_type)\n",
      "    assert isclose(result, expected, rel_tol=1e-9)\n",
      "\n",
      "# 2. Casos edge: descuento 0%, 100%, valores negativos\n",
      "@pytest.mark.parametrize(\n",
      "    \"price, discount_percent, user_type, expected\",\n",
      "    [\n",
      "        (100.0, 0, 'premium', 95.0),       # premium, 5% desc\n",
      "        (100.0, 100, 'premium', 0.0),      # premium, 105% desc, negativo\n",
      "        (100.0, 105, 'regular', -5.0),     # regular, >100% desc\n",
      "        (100.0, -10, 'regular', 110.0),    # descuento negativo, aumenta precio\n",
      "        (100.0, -5, 'premium', 100.0),     # premium, -5+5=0, sin descuento\n",
      "        (0.0, 50, 'regular', 0.0),         # precio cero\n",
      "    ]\n",
      ")\n",
      "def test_calculate_discount_edge(price, discount_percent, user_type, expected):\n",
      "    result = calculate_discount(price, discount_percent, user_type)\n",
      "    assert isclose(result, expected, rel_tol=1e-9)\n",
      "\n",
      "# 3. Casos de error: tipos incorrectos, valores inválidos\n",
      "@pytest.mark.parametrize(\n",
      "    \"price, discount_percent, user_type\",\n",
      "    [\n",
      "        (\"100\", 10, 'regular'),            # price no es float/int\n",
      "        (100.0, \"10\", 'regular'),          # discount_percent no es float/int\n",
      "        (100.0, 10, 'vip'),                # user_type no válido\n",
      "        (100.0, 10, ''),                   # user_type vacío\n",
      "        (100.0, None, 'regular'),          # discount_percent None\n",
      "        (None, 10, 'regular'),             # price None\n",
      "        (100.0, 10, None),                 # user_type None\n",
      "    ]\n",
      ")\n",
      "def test_calculate_discount_errors(price, discount_percent, user_type):\n",
      "    with pytest.raises(Exception):\n",
      "        calculate_discount(price, discount_percent, user_type)\n",
      "\n",
      "# 4. Test: Verifica que no modifica los argumentos originales\n",
      "def test_calculate_discount_no_side_effect():\n",
      "    price = 100.0\n",
      "    discount_percent = 10\n",
      "    user_type = 'premium'\n",
      "    calculate_discount(price, discount_percent, user_type)\n",
      "    assert price == 100.0\n",
      "    assert discount_percent == 10\n",
      "    assert user_type == 'premium'\n",
      "\n",
      "# 5. Test: Casos con decimales y precisión\n",
      "@pytest.mark.parametrize(\n",
      "    \"price, discount_percent, user_type, expected\",\n",
      "    [\n",
      "        (99.99, 12.5, 'regular', 87.49125),\n",
      "        (99.99, 12.5, 'premium', 82.49175),\n",
      "        (50.5, 50.5, 'regular', 25.025),\n",
      "    ]\n",
      ")\n",
      "def test_calculate_discount_decimals(price, discount_percent, user_type, expected):\n",
      "    result = calculate_discount(price, discount_percent, user_type)\n",
      "    assert isclose(result, expected, rel_tol=1e-7)\n",
      "\n",
      "# 6. Test: Case sensitivity en user_type\n",
      "def test_calculate_discount_user_type_case_sensitive():\n",
      "    # Debe tratar 'Premium' distinto de 'premium'\n",
      "    result_regular = calculate_discount(100, 10, 'Premium')\n",
      "    assert isclose(result_regular, 90.0, rel_tol=1e-9)\n",
      "    result_premium = calculate_discount(100, 10, 'premium')\n",
      "    assert isclose(result_premium, 85.0, rel_tol=1e-9)\n",
      "\n",
      "# 7. Test: user_type con espacios\n",
      "def test_calculate_discount_user_type_spaces():\n",
      "    result = calculate_discount(100, 10, ' premium ')\n",
      "    # No debe dar descuento extra\n",
      "    assert isclose(result, 90.0, rel_tol=1e-9)\n",
      "\n",
      "```\n",
      "\n",
      "**Notas:**\n",
      "- Cambia `from your_module import calculate_discount` si la función está en otro archivo.\n",
      "- Los tests cubren casos normales, edge, errores de tipo y valores, precisión decimal, sensibilidad de mayúsculas y espacios.\n",
      "- Se usa `isclose` para comparar floats y evitar errores de precisión.\n",
      "- Los tests de error esperan cualquier excepción porque la función no maneja errores explícitamente.\n",
      "\n",
      "Para ejecutar:\n",
      "```shell\n",
      "pytest test_calculate_discount.py\n",
      "```\n",
      "(guarda el código en `test_calculate_discount.py` o como prefieras).\n",
      "\n",
      "=== ANÁLISIS DE TESTS ===\n",
      "• Métodos de test: 7\n",
      "• Assertions: 9\n",
      "• Tests parametrizados: 4\n",
      "• Cobertura estimada: Alta\n"
     ]
    }
   ],
   "source": [
    "# Caso de uso: Generación de tests\n",
    "def generacion_tests_zero_shot():\n",
    "    print(\"=== CASO DE USO: GENERACIÓN DE TESTS ===\")\n",
    "    \n",
    "    funcion_a_testear = '''def calculate_discount(price, discount_percent, user_type):\n",
    "    \"\"\"Calculate final price after discount.\n",
    "    \n",
    "    Args:\n",
    "        price (float): Original price\n",
    "        discount_percent (float): Discount percentage (0-100)\n",
    "        user_type (str): 'premium' or 'regular'\n",
    "        \n",
    "    Returns:\n",
    "        float: Final price after discount\n",
    "    \"\"\"\n",
    "    if user_type == 'premium':\n",
    "        discount_percent += 5  # Extra 5% for premium users\n",
    "    \n",
    "    discount_amount = price * (discount_percent / 100)\n",
    "    return price - discount_amount'''\n",
    "    \n",
    "    prompt_tests = f\"\"\"Eres un QA engineer experto en testing de Python.\n",
    "    \n",
    "Genera tests unitarios completos para la siguiente función usando pytest.\n",
    "    \n",
    "Incluye tests para:\n",
    "1. Casos normales (diferentes tipos de usuario y descuentos)\n",
    "2. Casos edge (descuento 0%, 100%, valores negativos)\n",
    "3. Casos de error (tipos incorrectos, valores inválidos)\n",
    "4. Tests parametrizados cuando sea apropiado\n",
    "    \n",
    "Función a testear:\n",
    "```python\n",
    "{funcion_a_testear}\n",
    "```\n",
    "    \n",
    "Genera código de test completo y ejecutable:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_tests)])\n",
    "        print(\"TESTS GENERADOS:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(response.content)\n",
    "        \n",
    "        # Análisis básico de los tests generados\n",
    "        test_methods = response.content.count(\"def test_\")\n",
    "        assertions = response.content.count(\"assert\")\n",
    "        parametrize = response.content.count(\"@pytest.mark.parametrize\")\n",
    "        \n",
    "        print(\"\\n=== ANÁLISIS DE TESTS ===\")\n",
    "        print(f\"• Métodos de test: {test_methods}\")\n",
    "        print(f\"• Assertions: {assertions}\")\n",
    "        print(f\"• Tests parametrizados: {parametrize}\")\n",
    "        print(f\"• Cobertura estimada: {'Alta' if test_methods >= 5 else 'Media' if test_methods >= 3 else 'Baja'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar generación de tests\n",
    "generacion_tests_zero_shot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejores Prácticas y Limitaciones\n",
    "\n",
    "### ✅ Cuándo Usar Zero-Shot:\n",
    "- Tareas comunes y bien definidas\n",
    "- Cuando no tienes ejemplos disponibles\n",
    "- Para prototipado rápido\n",
    "- Tareas que requieren creatividad\n",
    "\n",
    "### ❌ Cuándo NO Usar Zero-Shot:\n",
    "- Formatos de salida muy específicos\n",
    "- Tareas de dominio muy especializado\n",
    "- Cuando la consistencia es crítica\n",
    "- Tareas complejas que requieren patrones específicos\n",
    "\n",
    "### 🎯 Mejores Prácticas:\n",
    "1. **Sé específico**: Detalla exactamente qué quieres\n",
    "2. **Define el formato**: Especifica cómo debe verse la salida\n",
    "3. **Establece restricciones**: Qué debe evitar o considerar\n",
    "4. **Usa roles**: Define quién debe \"ser\" el modelo\n",
    "5. **Itera y refina**: Mejora basándote en resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio final: Diseña tu propio prompt zero-shot\n",
    "def ejercicio_personalizado():\n",
    "    print(\"=== EJERCICIO PERSONAL ===\")\n",
    "    print(\"\\nDiseña un prompt zero-shot para esta tarea:\")\n",
    "    print(\"'Crear una descripción de trabajo atractiva para un puesto de desarrollador Python junior'\")\n",
    "    print(\"\\nEstructura sugerida:\")\n",
    "    print(\"1. Rol/Contexto del modelo\")\n",
    "    print(\"2. Tarea específica\")\n",
    "    print(\"3. Requisitos del formato\")\n",
    "    print(\"4. Restricciones importantes\")\n",
    "    print(\"\\nTu prompt aquí:\")\n",
    "    \n",
    "    # Espacio para que el estudiante diseñe su prompt\n",
    "    prompt_estudiante = \"\"\"# COLOCA TU PROMPT AQUÍ\n",
    "    \n",
    "# Ejemplo de estructura:\n",
    "# Eres un [ROL]...\n",
    "# Tarea: [TAREA ESPECÍFICA]...\n",
    "# Formato: [ESTRUCTURA DE SALIDA]...\n",
    "# Restricciones: [LIMITACIONES]...\n",
    "\"\"\"\n",
    "    \n",
    "    print(prompt_estudiante)\n",
    "    \n",
    "    # Prompt de ejemplo bien estructurado\n",
    "    ejemplo_prompt = \"\"\"Eres un HR Business Partner senior especializado en tecnología con 8 años de experiencia reclutando desarrolladores.\n",
    "    \n",
    "Tarea: Redacta una descripción de trabajo atractiva y realista para un puesto de Desarrollador Python Junior.\n",
    "    \n",
    "Formato requerido:\n",
    "- Título del puesto\n",
    "- Resumen ejecutivo (2-3 líneas)\n",
    "- Responsabilidades principales (4-5 puntos)\n",
    "- Requisitos técnicos (separar esenciales de deseables)\n",
    "- Beneficios y cultura de empresa\n",
    "- Llamada a la acción\n",
    "    \n",
    "Restricciones:\n",
    "- Máximo 400 palabras\n",
    "- Lenguaje inclusivo y accesible\n",
    "- Enfócate en crecimiento profesional\n",
    "- Evita jerga técnica excesiva\n",
    "- Sé honesto sobre el nivel junior\n",
    "    \n",
    "Descripción de trabajo:\"\"\"\n",
    "    \n",
    "    print(\"\\n=== EJEMPLO DE PROMPT BIEN ESTRUCTURADO ===\")\n",
    "    print(ejemplo_prompt)\n",
    "    \n",
    "    # Opcional: probar el prompt ejemplo\n",
    "    print(\"\\n¿Quieres ver el resultado del prompt ejemplo? (y/n)\")\n",
    "    # En un entorno real, aquí habría input del usuario\n",
    "    \n",
    "ejercicio_personalizado()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Zero-shot prompting** es efectivo para tareas comunes sin necesidad de ejemplos\n",
    "2. **Estructura clara** del prompt mejora significativamente los resultados\n",
    "3. **Roles específicos** generan respuestas más enfocadas y expertas\n",
    "4. **Instrucciones graduales** ayudan con tareas complejas\n",
    "5. **Formato definido** asegura salidas consistentes y útiles\n",
    "\n",
    "## Próximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos **Few-Shot Prompting**, donde aprenderemos a usar ejemplos específicos para guiar el comportamiento del modelo y lograr mayor consistencia en tareas especializadas.\n",
    "\n",
    "### Para Practicar:\n",
    "1. Diseña prompts zero-shot para diferentes tipos de tareas\n",
    "2. Experimenta con diferentes roles y contextos\n",
    "3. Compara resultados con y sin estructura específica\n",
    "4. Mide la consistencia en múltiples ejecuciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
