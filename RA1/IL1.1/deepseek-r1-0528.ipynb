{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6260bf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking about the capital of France. That's a straightforward geography question. \n",
      "\n",
      "Hmm, this seems like a very basic fact check - maybe a student doing homework or someone confirming trivia. The answer is definitely Paris, but I should make it helpful by adding context. \n",
      "\n",
      "I recall Paris isn't just the political capital but also the cultural heart of France. The user might appreciate knowing it's also called the \"City of Light.\" Should I mention other cities like Lyon or Marseille? No, that might confuse them since the question is specifically about the capital. \n",
      "\n",
      "The response should be clear and inviting - ending with an offer for more details in case they're planning a trip or studying. Simple but polished, like a tour guide's opening line.\n",
      "</think>\n",
      "The capital of France is **Paris**.  \n",
      "\n",
      "### Key Facts about Paris:\n",
      "- **Location**: Situated in the north-central part of France, along the Seine River.\n",
      "- **Significance**:  \n",
      "  - Political, economic, and cultural center of France.  \n",
      "  - Home to landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.  \n",
      "  - Often called the \"City of Light\" (*La Ville LumiÃ¨re*).  \n",
      "- **Population**: Over 2.1 million in the city proper (12 million in the metro area).  \n",
      "\n",
      "Let me know if you'd like more details about Paris or France! ðŸ‡«ðŸ‡·\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"deepseek/DeepSeek-R1-0528\"\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        UserMessage(\"What is the capital of France?\"),\n",
    "    ],\n",
    "    max_tokens=1000,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
