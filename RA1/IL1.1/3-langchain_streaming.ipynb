{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hfn0f7nyumn",
   "metadata": {},
   "source": [
    "# 3. LangChain Streaming - Respuestas en Tiempo Real\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender qué es el streaming y cuándo usarlo\n",
    "- Implementar streaming con LangChain\n",
    "- Manejar chunks de datos en tiempo real\n",
    "- Construir interfaces de usuario reactivas\n",
    "\n",
    "## ¿Qué es el Streaming?\n",
    "\n",
    "El streaming permite recibir la respuesta del modelo **token por token** conforme se genera, en lugar de esperar a que termine completamente. Esto mejora significativamente la experiencia de usuario en aplicaciones interactivas.\n",
    "\n",
    "### Ventajas del Streaming:\n",
    "- **Percepción de velocidad**: El usuario ve progreso inmediato\n",
    "- **Mejor UX**: Interfaces más reactivas e interactivas  \n",
    "- **Engagement**: Mantiene la atención del usuario\n",
    "- **Debugging**: Permite ver el proceso de generación\n",
    "\n",
    "### Casos de Uso Ideales:\n",
    "- Chatbots y asistentes conversacionales\n",
    "- Generación de contenido largo\n",
    "- Aplicaciones web interactivas\n",
    "- Demostraciones en vivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa694f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas correctamente para streaming\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Bibliotecas importadas correctamente para streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13f037cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo configurado con streaming habilitado\n",
      "Modelo: gpt-4o\n",
      "Streaming: True\n"
     ]
    }
   ],
   "source": [
    "# Configuración del modelo con streaming habilitado\n",
    "try:\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "         base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "         api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "         model=\"gpt-4o\",\n",
    "         streaming=True,  # ¡Importante: habilitar streaming!\n",
    "         temperature=0.7\n",
    "     )\n",
    "    # llm = ChatOpenAI(\n",
    "    #     base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "    #     api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "    #     model = \"openai/gpt-4.1\",               # modelo DeepSeek\n",
    "    #     temperature=0.7,\n",
    "    #     streaming=True, \n",
    "    #     max_tokens=150\n",
    "    # )\n",
    "    \n",
    "    print(\"✓ Modelo configurado con streaming habilitado\")\n",
    "    print(f\"Modelo: {llm.model_name}\")\n",
    "    print(f\"Streaming: {llm.streaming}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error en configuración: {e}\")\n",
    "    print(\"Verifica las variables de entorno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da0d27",
   "metadata": {},
   "source": [
    "## Streaming Básico\n",
    "\n",
    "El método `.stream()` devuelve un generador que produce chunks de texto conforme se generan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1f31f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING EN TIEMPO REAL ===\n",
      "Generando respuesta...\n",
      "--------------------------------------------------\n",
      "✗ Error en streaming: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 53609 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 53609 seconds before retrying.'}}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo básico de streaming\n",
    "def streaming_basico():\n",
    "    prompt = \"Cuéntame una historia breve sobre los beneficios de el oregano \"\n",
    "    \n",
    "    print(\"=== STREAMING EN TIEMPO REAL ===\")\n",
    "    print(\"Generando respuesta...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # stream() devuelve un generador de chunks\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Imprimir cada chunk sin nueva línea\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.01)  # Pequeña pausa para simular streaming visual\n",
    "            \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"✓ Streaming completado\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error en streaming: {e}\")\n",
    "\n",
    "# Ejecutar streaming básico\n",
    "streaming_basico()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10285d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1A: SPINNER SIMPLE ===\n",
      "Generando respuesta...\n",
      "\n",
      "✓ Completado!   l orégano aporta beneficios antioxidantes, antimicrobianos y antiinflamatorios. Mejora la digestión, refuerza el sistema inmunológico, combate infecciones y contribuye a la salud respiratoria. Sus compuestos ayudan a prevenir enfermedades y promueven el bienestar general.\n",
      "\n",
      "Respuesta completa:\n",
      "El orégano aporta beneficios antioxidantes, antimicrobianos y antiinflamatorios. Mejora la digestión, refuerza el sistema inmunológico, combate infecciones y contribuye a la salud respiratoria. Sus compuestos ayudan a prevenir enfermedades y promueven el bienestar general.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "import re\n",
    "from itertools import cycle\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EJERCICIO 1: INDICADORES DE PROGRESO\n",
    "# =============================================================================\n",
    "\n",
    "def ejercicio1_spinner_simple():\n",
    "    \"\"\"Spinner básico que rota mientras llegan chunks\"\"\"\n",
    "  \n",
    "    spinner = cycle(['|', '/', '-', '\\\\'])\n",
    "    prompt = \"rwsumido en 30 palabras :Explica los beneficios del oregano para la salud\"\n",
    "    \n",
    "    print(\"=== EJERCICIO 1A: SPINNER SIMPLE ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    \n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        \n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Mostrar spinner\n",
    "            sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            \n",
    "        # Limpiar spinner y mostrar resultado\n",
    "        sys.stdout.write('\\r✓ Completado!   \\n')\n",
    "        print(f\"\\nRespuesta completa:\\n{response_text}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "ejercicio1_spinner_simple()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8852d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1A: SPINNER SIMPLE ===\n",
      "Generando respuesta...\n",
      "\n",
      "                    égano ofrece propiedades antioxidantes, antiinflamatorias y antimicrobianas. Favorece la digestión, fortalece el sistema inmunológico, protege contra infecciones y contribuye a la salud cardiovascular, gracias a sus compuestos como carvacrol y timol.\n",
      "✓ Completado!\n",
      "\n",
      "Respuesta completa:\n",
      "El orégano ofrece propiedades antioxidantes, antiinflamatorias y antimicrobianas. Favorece la digestión, fortalece el sistema inmunológico, protege contra infecciones y contribuye a la salud cardiovascular, gracias a sus compuestos como carvacrol y timol.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#modificado \n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "from itertools import cycle\n",
    "\n",
    "def spinner_task(stop_event):\n",
    "    spinner = cycle(['|', '/', '-', '\\\\'])\n",
    "    while not stop_event.is_set():\n",
    "        sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.1)\n",
    "    sys.stdout.write('\\r' + ' ' * 20 + '\\r')  # limpia la línea del spinner\n",
    "\n",
    "def ejercicio1_spinner_simple():\n",
    "    prompt = \"resumen en 30 palabras :Explica los beneficios del oregano para la salud\"\n",
    "    print(\"=== EJERCICIO 1A: SPINNER SIMPLE ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    response_text = \"\"\n",
    "    stop_event = threading.Event()\n",
    "    spinner_thread = threading.Thread(target=spinner_task, args=(stop_event,))\n",
    "    spinner_thread.start()\n",
    "\n",
    "    try:\n",
    "        # Recibe e imprime chunks normalmente (sin spinner aquí)\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "        stop_event.set()\n",
    "        spinner_thread.join()\n",
    "        print(\"\\n✓ Completado!\")\n",
    "        print(f\"\\nRespuesta completa:\\n{response_text}\\n\")\n",
    "    except Exception as e:\n",
    "        stop_event.set()\n",
    "        spinner_thread.join()\n",
    "        print(f\"\\nError: {e}\")\n",
    "\n",
    "ejercicio1_spinner_simple()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2190b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1B: BARRA DE PROGRESO ===\n",
      "[██████████████████████████████] 100% (117 chars)\n",
      "\n",
      "\n",
      "Respuesta final:\n",
      "La fotosíntesis es el proceso donde las plantas convierten luz solar, agua y dióxido de carbono en glucosa y oxígeno.\n",
      "\n",
      "✅ Barra de progreso completada!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def ejercicio1_barra_progreso():\n",
    "    \"\"\"Barra de progreso visual basada en longitud de texto generado\"\"\"\n",
    "    \n",
    "    prompt = \"resume en 20 palabras:Describe el proceso de fotosíntesis en las plantas\"\n",
    "    print(\"=== EJERCICIO 1B: BARRA DE PROGRESO ===\")\n",
    "    \n",
    "    response_text = \"\"\n",
    "    last_percent = 0\n",
    "    bar_length = 30\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Progreso estimado basado en cantidad de caracteres\n",
    "            total_estimate = 30  # puedes ajustar según lo largo que esperas que sea la respuesta\n",
    "            progress = min(len(response_text) / total_estimate, 1.0)\n",
    "            \n",
    "            filled_length = int(bar_length * progress)\n",
    "            bar = '█' * filled_length + '░' * (bar_length - filled_length)\n",
    "            percent = int(progress * 100)\n",
    "            \n",
    "            # Solo actualizar si hay un cambio real en porcentaje\n",
    "            if percent != last_percent:\n",
    "                sys.stdout.write(f'\\r[{bar}] {percent}% ({len(response_text)} chars)')\n",
    "                sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "            \n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        # Completa la barra al final\n",
    "        sys.stdout.write('\\r[' + '█'*bar_length + '] 100% (' + str(len(response_text)) + ' chars)\\n')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        print(f\"\\n\\nRespuesta final:\\n{response_text}\\n\")\n",
    "        print(\"✅ Barra de progreso completada!\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "\n",
    "ejercicio1_barra_progreso()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6214408",
   "metadata": {},
   "source": [
    "## Comparación: Streaming vs No-Streaming\n",
    "\n",
    "Veamos la diferencia en experiencia de usuario entre ambos enfoques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db8e5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACIÓN: STREAMING vs NO-STREAMING ===\\n\n",
      "1. SIN STREAMING:\n",
      "--------------------\n",
      "Esperando respuesta completa...\n",
      "\\n[Respuesta recibida después de 3.09 segundos]\n",
      "El orégano es una hierba aromática que ofrece numerosos beneficios para la salud. Su potente contenido de antioxidantes ayuda a combatir el daño celular y a fortalecer el sistema inmunológico. Además, posee propiedades antimicrobianas que pueden ayudar a combatir infecciones bacterianas y fúngicas. El orégano también es conocido por sus efectos antiinflamatorios, lo que puede ser beneficioso para condiciones como la artritis. Su consumo puede favorecer la digestión, aliviando problemas gastrointestinales y promoviendo la salud intestinal. Asimismo, su aceite esencial contiene compuestos como el carvacrol y el timol, que han demostrado propiedades terapéuticas. Incorporar orégano en la dieta no solo realza el sabor de los platillos, sino que también contribuye al bienestar general, convirtiéndolo en un aliado natural en la cocina y en la salud.\n",
      "\\n============================================================\\n\n",
      "2. CON STREAMING:\n",
      "------------------\n",
      "Respuesta en tiempo real:\n",
      "Error: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 53865 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 53865 seconds before retrying.'}}\n",
      "\\n============================================================\n",
      "OBSERVACIONES:\n",
      "- Sin streaming: El usuario espera sin feedback\n",
      "- Con streaming: El usuario ve progreso inmediato\n",
      "- Mejor percepción de velocidad con streaming\n",
      "- Streaming es especial para respuestas largas\n"
     ]
    }
   ],
   "source": [
    "# Comparación entre streaming y no-streaming\n",
    "def comparar_streaming():\n",
    "\n",
    "    # Modelo sin streaming\n",
    "    llm_no_stream = ChatOpenAI(\n",
    "        base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "        #model = \"openai/gpt-4.1\",               \n",
    "        model = \"openai/gpt-4o-mini\",\n",
    "        temperature=0.7,\n",
    "        streaming=False  # Sin streaming\n",
    "       \n",
    "    )\n",
    "    \n",
    "    prompt = \"resumido en 150 palabras :Escribe un párrafo sobre beneficions del oregano\"\n",
    "    \n",
    "    print(\"=== COMPARACIÓN: STREAMING vs NO-STREAMING ===\\\\n\")\n",
    "    \n",
    "    # 1. Sin streaming\n",
    "    print(\"1. SIN STREAMING:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Esperando respuesta completa...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = llm_no_stream.invoke([HumanMessage(content=prompt)])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\\\n[Respuesta recibida después de {end_time - start_time:.2f} segundos]\")\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60 + \"\\\\n\")\n",
    "    \n",
    "    # 2. Con streaming\n",
    "    print(\"2. CON STREAMING:\")\n",
    "    print(\"-\" * 18)\n",
    "    print(\"Respuesta en tiempo real:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.03)  # Simular pausa para efecto visual\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\\\n\\\\n[Streaming completado en {end_time - start_time:.2f} segundos]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"OBSERVACIONES:\")\n",
    "    print(\"- Sin streaming: El usuario espera sin feedback\")\n",
    "    print(\"- Con streaming: El usuario ve progreso inmediato\")\n",
    "    print(\"- Mejor percepción de velocidad con streaming\")\n",
    "    print(\"- Streaming es especial para respuestas largas\")\n",
    "\n",
    "# Ejecutar comparación\n",
    "comparar_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ad79d",
   "metadata": {},
   "source": [
    "## Implementación de un Chatbot Simple con Streaming\n",
    "\n",
    "Creemos un chatbot básico que demuestre el streaming en un contexto práctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot simple con streaming\n",
    "def chatbot_streaming():\n",
    "    print(\"=== CHATBOT CON STREAMING ===\")\n",
    "    print(\"Escribe 'salir' para terminar la conversación\\\\n\")\n",
    "    \n",
    "    # Configurar asistente con personalidad\n",
    "    system_message = \"\"\"Eres un asistente útil y amigable especializado en tecnología. \n",
    "    Respondes de manera clara y concisa, y siempre intentas ser educativo.\"\"\"\n",
    "    \n",
    "    while True:\n",
    "        # Obtener input del usuario\n",
    "        user_input = input(\"\\\\n🧑 Tú: \")\n",
    "        \n",
    "        if user_input.lower() in ['salir', 'exit', 'quit']:\n",
    "            print(\"\\\\n👋 ¡Hasta luego!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input.strip():\n",
    "            continue\n",
    "            \n",
    "        print(\"\\\\n🤖 Asistente: \", end=\"\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Streaming de la respuesta\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "            \n",
    "            # Convertir a formato LangChain\n",
    "            from langchain.schema import SystemMessage\n",
    "            lc_messages = [\n",
    "                SystemMessage(content=system_message),\n",
    "                HumanMessage(content=user_input)\n",
    "            ]\n",
    "            \n",
    "            full_response = \"\"\n",
    "            for chunk in llm.stream(lc_messages):\n",
    "                content = chunk.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "                time.sleep(0.02)\n",
    "                \n",
    "            print()  # Nueva línea al final\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\\\n\\\\n⏸️ Interrumpido por el usuario\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n❌ Error: {e}\")\n",
    "            \n",
    "    print(\"\\\\n¡Gracias por usar el chatbot!\")\n",
    "\n",
    "# Ejecutar chatbot (¡Pruébalo!)\n",
    "chatbot_streaming() \n",
    " # Descomenta esta línea para ejecutar\n",
    "\n",
    "print(\"💡 Descomenta la línea anterior para probar el chatbot interactivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060e43c",
   "metadata": {},
   "source": [
    "## Streaming Avanzado con Manejo de Chunks\n",
    "\n",
    "Podemos procesar cada chunk individualmente para crear experiencias más sofisticadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fa1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming con análisis de chunks\n",
    "def streaming_avanzado():\n",
    "    prompt = \"Explica qué es la inteligencia artificial y cómo funciona el machine learning\"\n",
    "    \n",
    "    print(\"=== STREAMING AVANZADO CON ANÁLISIS ===\")\n",
    "    print(\"Analizando chunks conforme llegan...\\n\")\n",
    "    \n",
    "    # Variables para estadísticas\n",
    "    chunk_count = 0\n",
    "    total_content = \"\"\n",
    "    words_processed = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            chunk_count += 1\n",
    "            content = chunk.content\n",
    "            total_content += content\n",
    "            \n",
    "            # Contar palabras aproximadas\n",
    "            if content.strip():\n",
    "                words_in_chunk = len(content.split())\n",
    "                words_processed += words_in_chunk\n",
    "            \n",
    "            # Mostrar progreso cada 10 chunks\n",
    "            if chunk_count % 10 == 0:\n",
    "                print(f\"\\\\n[Progreso: {chunk_count} chunks, ~{words_processed} palabras]\\\\n\")\n",
    "            \n",
    "            # Imprimir el contenido\n",
    "            print(content, end=\"\", flush=True)\n",
    "            time.sleep(0.02)  # Pausa ligeramente más larga para ver el análisis\n",
    "        \n",
    "        # Estadísticas finales\n",
    "        print(f\"\\\\n\\\\n=== ESTADÍSTICAS FINALES ===\")\n",
    "        print(f\"Total de chunks: {chunk_count}\")\n",
    "        print(f\"Palabras aproximadas: {words_processed}\")\n",
    "        print(f\"Caracteres totales: {len(total_content)}\")\n",
    "        print(f\"Promedio chars/chunk: {len(total_content)/chunk_count if chunk_count > 0 else 0:.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\n✗ Error: {e}\")\n",
    "\n",
    "# Ejecutar streaming avanzado\n",
    "streaming_avanzado()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac251a9d",
   "metadata": {},
   "source": [
    "## Consideraciones Técnicas del Streaming\n",
    "\n",
    "### Cuándo Usar Streaming:\n",
    "✅ **SÍ usar streaming:**\n",
    "- Respuestas largas (>100 tokens)\n",
    "- Aplicaciones interactivas\n",
    "- Chatbots y asistentes\n",
    "- Demostraciones en vivo\n",
    "- Cuando la UX es prioritaria\n",
    "\n",
    "❌ **NO usar streaming:**\n",
    "- Respuestas muy cortas\n",
    "- Procesamiento batch\n",
    "- APIs de backend sin interfaz\n",
    "- Cuando necesitas la respuesta completa antes de procesar\n",
    "\n",
    "### Mejores Prácticas:\n",
    "1. **Manejo de errores**: Siempre incluye try/catch\n",
    "2. **Indicadores visuales**: Muestra progreso al usuario\n",
    "3. **Cancelación**: Permite al usuario interrumpir\n",
    "4. **Buffer management**: Para interfaces web, considera buffering\n",
    "5. **Performance**: Monitorea el uso de recursos\n",
    "\n",
    "## Ejercicios Prácticos\n",
    "\n",
    "### Ejercicio 1: Indicador de Progreso\n",
    "Modifica el código para mostrar un indicador de progreso (spinner, barra, porcentaje).\n",
    "\n",
    "### Ejercicio 2: Streaming con Filtros\n",
    "Implementa streaming que filtre o procese chunks específicos (ej: resaltar palabras clave).\n",
    "\n",
    "### Ejercicio 3: Chatbot Mejorado\n",
    "Extiende el chatbot con:\n",
    "- Historial de conversación\n",
    "- Comandos especiales (/help, /clear)\n",
    "- Diferentes personalidades\n",
    "\n",
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Streaming** mejora la percepción de velocidad\n",
    "2. **Chunks** se procesan individualmente en tiempo real\n",
    "3. **UX** es significativamente mejor con streaming\n",
    "4. **Implementación** requiere manejo cuidadoso de generadores\n",
    "5. **Casos de uso** específicos donde streaming aporta valor\n",
    "\n",
    "## Próximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos la **memoria en LangChain**, que nos permite mantener contexto entre múltiples interacciones del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced2c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando respuesta...\n",
      "✅ Completado!        \n",
      "\n",
      "**Python** es un **lenguaje de programación** de alto nivel, interpretado, multiparadigma (soporta programación orientada a objetos, imperativa y funcional), y de propósito general. Fue creado por **Guido van Rossum** y publicado en 1991. Su diseño enfatiza la legibilidad del código y una sintaxis sencilla que permite a los programadores expresar conceptos en menos líneas de código que otros lenguajes.\n",
      "\n",
      "### Ventajas de Python\n",
      "\n",
      "1. **Sintaxis sencilla y legible**  \n",
      "   Python está diseñado para ser fácil de leer y escribir, lo que facilita el aprendizaje y el desarrollo rápido.\n",
      "\n",
      "2. **Gran comunidad y soporte**  \n",
      "   Cuenta con una comunidad activa que aporta miles de librerías\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#import time\n",
    "from itertools import cycle\n",
    "#from langchain_openai import ChatOpenAI\n",
    "#from langchain.schema import HumanMessage\n",
    "\n",
    "def spinner_progreso():\n",
    "    \"\"\"Spinner que rota mientras llegan los chunks\"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Caracteres del spinner\n",
    "    spinner = cycle(['⠋', '⠙', '⠹', '⠸', '⠼', '⠴', '⠦', '⠧', '⠇', '⠏'])\n",
    "    \n",
    "    prompt = \"Explica qué es Python y sus ventajas\"\n",
    "    response_text = \"\"\n",
    "    \n",
    "    print(\"Generando respuesta...\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Mostrar spinner\n",
    "            sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        # Limpiar spinner y mostrar resultado\n",
    "        sys.stdout.write('\\r✅ Completado!        \\n\\n')\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "spinner_progreso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b67c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Barra de Progreso ===\n",
      "[█████████████████████████] 100% (617 chars)\n",
      "\n",
      "Respuesta completa:\n",
      "Claro, aquí tienes una descripción paso a paso del proceso de **machine learning** (aprendizaje automático):\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Definición del problema**\n",
      "   - Identifica y comprende el problema que deseas resolver.\n",
      "   - Ejemplo: ¿Quieres clasificar correos como spam/no spam?\n",
      "\n",
      "### 2. **Recolección de datos**\n",
      "   - Obtén datos relevantes para el problema.\n",
      "   - Pueden provenir de bases de datos, sensores, web, etc.\n",
      "\n",
      "### 3. **Preprocesamiento de datos**\n",
      "   - Limpieza: Elimina duplicados, corrige errores y trata valores faltantes.\n",
      "   - Transformación: Normaliza o estandariza datos, convierte variables categóricas en num\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "def barra_progreso():\n",
    "    \"\"\"Barra de progreso basada en caracteres generados\"\"\"\n",
    "    \n",
    "    prompt = \"Describe el proceso de machine learning paso a paso\"\n",
    "    response_text = \"\"\n",
    "    bar_length = 25\n",
    "    estimated_total = 400  # Estimación de caracteres esperados\n",
    "    \n",
    "    print(\"=== Barra de Progreso ===\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Calcular progreso\n",
    "            progress = min(len(response_text) / estimated_total, 1.0)\n",
    "            filled = int(bar_length * progress)\n",
    "            \n",
    "            # Crear barra visual\n",
    "            bar = '█' * filled + '░' * (bar_length - filled)\n",
    "            percent = int(progress * 100)\n",
    "            \n",
    "            # Actualizar barra\n",
    "            sys.stdout.write(f'\\r[{bar}] {percent}% ({len(response_text)} chars)')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        # Completar al 100%\n",
    "        sys.stdout.write(f'\\r[{\"█\" * bar_length}] 100% ({len(response_text)} chars)\\n\\n')\n",
    "        print(\"Respuesta completa:\")\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "barra_progreso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6143ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Contador de Palabras ===\n",
      "Generando respuesta...\n",
      "\n",
      "📝 Palabras: 103 | Caracteres: 727\n",
      "\n",
      "✅ Generación completada!\n",
      "📊 Estadísticas finales: 103 palabras, 727 caracteres\n",
      "\n",
      "Respuesta:\n",
      "La inteligencia artificial (IA) ofrece numerosos beneficios en diferentes ámbitos de la vida y sectores productivos. Algunos de los principales son:\n",
      "\n",
      "1. **Automatización de tareas**: Permite que procesos repetitivos o complejos se realicen de forma automática, ahorrando tiempo y reduciendo errores humanos.\n",
      "\n",
      "2. **Mejora en la toma de decisiones**: La IA puede analizar grandes cantidades de datos y ofrecer recomendaciones o predicciones más precisas que las realizadas manualmente.\n",
      "\n",
      "3. **Personalización**: En áreas como el comercio electrónico, la educación y la salud, la IA puede adaptar productos, servicios o contenidos a las necesidades y preferencias individuales de los usuarios.\n",
      "\n",
      "4. **Eficiencia operativa**: Ayuda a\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def contador_palabras():\n",
    "    \"\"\"Muestra el conteo de palabras conforme se genera el texto\"\"\"\n",
    "    \n",
    "    prompt = \"Cuéntame sobre los beneficios de la inteligencia artificial\"\n",
    "    response_text = \"\"\n",
    "    \n",
    "    print(\"=== Contador de Palabras ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Contar palabras\n",
    "            words = len(re.findall(r'\\b\\w+\\b', response_text))\n",
    "            chars = len(response_text)\n",
    "            \n",
    "            # Mostrar progreso\n",
    "            sys.stdout.write(f'\\r📝 Palabras: {words} | Caracteres: {chars}')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(f\"\\n\\n✅ Generación completada!\")\n",
    "        print(f\"📊 Estadísticas finales: {words} palabras, {chars} caracteres\\n\")\n",
    "        print(\"Respuesta:\")\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "contador_palabras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4604485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING CON RESALTADO DE PALABRAS CLAVE ===\n",
      "🔍 Palabras clave: python, machine learning, inteligencia artificial, algoritmo, datos, modelo\n",
      "\n",
      "Respuesta (palabras clave resaltadas con *):\n",
      "--------------------------------------------------\n",
      "***PYTHON*** es un lenguaje de programación de alto nivel, de propósito general, que se caracteriza por ser sencillo, legible y fácil de aprender. Fue creado a finales de los años 80 y desde entonces ha ganado enorme popularidad, especialmente en áreas como ciencia de *DATOS*, desarrollo web, automatización y, de manera destacada, en **machine learning (aprendizaje automático)** e **inteligencia artificial (IA)**.\n",
      "\n",
      "### ¿Qué es *PYTHON*?\n",
      "\n",
      "- **Sintaxis clara y sencilla**, lo que facilita el desarrollo y mantenimiento de código.\n",
      "- Es **multiparadigma**, permitiendo programación orientada a objetos, imperativa y funcional.\n",
      "- Posee una **gran comunidad** y una **amplia colección de bibliotecas\n",
      "--------------------------------------------------\n",
      "✅ Streaming completado!\n",
      "🎯 Palabras clave resaltadas: 3\n"
     ]
    }
   ],
   "source": [
    "def streaming_con_resaltado():\n",
    "    \"\"\"Resalta palabras clave específicas durante el streaming\"\"\"\n",
    "    \n",
    "    # Palabras clave a resaltar\n",
    "    keywords = [\"python\", \"machine learning\", \"inteligencia artificial\", \"algoritmo\", \"datos\", \"modelo\"]\n",
    "    \n",
    "    prompt = \"Explica qué es Python y cómo se usa en machine learning e inteligencia artificial\"\n",
    "    \n",
    "    print(\"=== STREAMING CON RESALTADO DE PALABRAS CLAVE ===\")\n",
    "    print(f\"🔍 Palabras clave: {', '.join(keywords)}\\n\")\n",
    "    print(\"Respuesta (palabras clave resaltadas con *):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response_text = \"\"\n",
    "    highlighted_count = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            content = chunk.content\n",
    "            response_text += content\n",
    "            \n",
    "            # Procesar cada chunk para resaltar palabras clave\n",
    "            processed_content = content\n",
    "            for keyword in keywords:\n",
    "                # Buscar la palabra clave (insensible a mayúsculas/minúsculas)\n",
    "                pattern = re.compile(re.escape(keyword), re.IGNORECASE)\n",
    "                if pattern.search(processed_content):\n",
    "                    processed_content = pattern.sub(f\"*{keyword.upper()}*\", processed_content)\n",
    "                    highlighted_count += 1\n",
    "            \n",
    "            # Mostrar el chunk procesado\n",
    "            print(processed_content, end=\"\", flush=True)\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(f\"\\n{'-' * 50}\")\n",
    "        print(f\"✅ Streaming completado!\")\n",
    "        print(f\"🎯 Palabras clave resaltadas: {highlighted_count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "streaming_con_resaltado()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c68777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bibliotecas importadas correctamente con SystemMessage\n",
      "🤖 === CHATBOT MEJORADO CON STREAMING ===\n",
      "💡 Escribe /help para ver comandos disponibles\n",
      "🎭 Personalidad inicial: asistente\n",
      "---------------------------------------------\n",
      "\n",
      "🤖 Bot (asistente): ¡Hola! ¿En qué puedo ayudarte hoy?\n",
      "\n",
      "❌ Uso: /personalidad [nombre]\n",
      "\n",
      "=== 🎭 PERSONALIDADES DISPONIBLES ===\n",
      "➤ asistente: Eres un asistente útil y profesional. Respondes de manera clara y concisa.\n",
      "   amigable: Eres muy amigable y casual. Usas emojis y un tono relajado. 😊\n",
      "   tecnico: Eres un experto técnico. Das respuestas detalladas y precisas con terminología específica.\n",
      "   creativo: Eres muy creativo e imaginativo. Usas metáforas y ejemplos únicos.\n",
      "   profesor: Eres un profesor paciente. Explicas paso a paso y das ejemplos educativos.\n",
      "========================================\n",
      "\n",
      "🤖 Bot (asistente): ¡Hola de nuevo! ¿Cómo puedo ayudarte?\n",
      "\n",
      "🤖 Bot (asistente): Soy un asistente virtual creado para ayudarte. No tengo un nombre propio, pero puedes llamarme simplemente \"Asistente\". ¿En qué puedo ayudarte hoy?\n",
      "\n",
      "🤖 Bot (asistente): Me llamo Asistente. Estoy aquí para ayudarte con cualquier pregunta o tarea que tengas. ¿En qué puedo ayudarte hoy?\n",
      "\n",
      "🤖 Bot (asistente): Un beneficio del orégano es que tiene propiedades antioxidantes, lo que ayuda a proteger las células del cuerpo contra el daño causado por los radicales libres.\n",
      "\n",
      "🤖 Bot (asistente): Un beneficio del orégano es que ayuda a fortalecer el sistema inmunológico gracias a sus compuestos antimicrobianos y antiinflamatorios.\n",
      "\n",
      "🤖 Bot (asistente): ¡Perfecto! Si necesitas ayuda en el futuro, aquí estaré. ¡Hasta luego!\n"
     ]
    }
   ],
   "source": [
    "# ✅ IMPORTACIONES CORREGIDAS\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "from itertools import cycle\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage  # ← Aquí estaba el problema\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"✅ Bibliotecas importadas correctamente con SystemMessage\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ChatbotMejorado:\n",
    "    def __init__(self):\n",
    "        self.historial = []\n",
    "        self.personalidad_actual = \"asistente\"\n",
    "        self.personalidades = {\n",
    "            \"asistente\": \"Eres un asistente útil y profesional. Respondes de manera clara y concisa.\",\n",
    "            \"amigable\": \"Eres muy amigable y casual. Usas emojis y un tono relajado. 😊\",\n",
    "            \"tecnico\": \"Eres un experto técnico. Das respuestas detalladas y precisas con terminología específica.\",\n",
    "            \"creativo\": \"Eres muy creativo e imaginativo. Usas metáforas y ejemplos únicos.\",\n",
    "            \"profesor\": \"Eres un profesor paciente. Explicas paso a paso y das ejemplos educativos.\"\n",
    "        }\n",
    "    \n",
    "    def mostrar_ayuda(self):\n",
    "        \"\"\"Muestra los comandos disponibles\"\"\"\n",
    "        print(\"\\n=== 📋 COMANDOS DISPONIBLES ===\")\n",
    "        print(\"🔧 /help - Muestra esta ayuda\")\n",
    "        print(\"🗑️  /clear - Limpia el historial\")\n",
    "        print(\"👤 /personalidad [nombre] - Cambia personalidad\")\n",
    "        print(\"📝 /personalidades - Lista personalidades disponibles\") \n",
    "        print(\"📊 /stats - Muestra estadísticas de la conversación\")\n",
    "        print(\"💾 /historial - Muestra historial completo\")\n",
    "        print(\"🚪 /salir - Termina la conversación\")\n",
    "        print(\"=\" * 35)\n",
    "    \n",
    "    def mostrar_personalidades(self):\n",
    "        \"\"\"Lista las personalidades disponibles\"\"\"\n",
    "        print(\"\\n=== 🎭 PERSONALIDADES DISPONIBLES ===\")\n",
    "        for nombre, descripcion in self.personalidades.items():\n",
    "            marca = \"➤\" if nombre == self.personalidad_actual else \"  \"\n",
    "            print(f\"{marca} {nombre}: {descripcion}\")\n",
    "        print(\"=\" * 40)\n",
    "    \n",
    "    def cambiar_personalidad(self, nueva_personalidad):\n",
    "        \"\"\"Cambia la personalidad del chatbot\"\"\"\n",
    "        if nueva_personalidad in self.personalidades:\n",
    "            self.personalidad_actual = nueva_personalidad\n",
    "            print(f\"\\n✅ Personalidad cambiada a: {nueva_personalidad}\")\n",
    "            print(f\"📝 {self.personalidades[nueva_personalidad]}\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Personalidad '{nueva_personalidad}' no encontrada\")\n",
    "            self.mostrar_personalidades()\n",
    "    \n",
    "    def limpiar_historial(self):\n",
    "        \"\"\"Limpia el historial de conversación\"\"\"\n",
    "        self.historial = []\n",
    "        print(\"\\n🗑️ Historial limpiado correctamente\")\n",
    "    \n",
    "    def mostrar_estadisticas(self):\n",
    "        \"\"\"Muestra estadísticas de la conversación\"\"\"\n",
    "        if not self.historial:\n",
    "            print(\"\\n📊 No hay estadísticas disponibles (historial vacío)\")\n",
    "            return\n",
    "        \n",
    "        mensajes_usuario = sum(1 for msg in self.historial if isinstance(msg, HumanMessage))\n",
    "        mensajes_bot = sum(1 for msg in self.historial if isinstance(msg, AIMessage))\n",
    "        \n",
    "        print(f\"\\n=== 📊 ESTADÍSTICAS ===\")\n",
    "        print(f\"💬 Mensajes del usuario: {mensajes_usuario}\")\n",
    "        print(f\"🤖 Respuestas del bot: {mensajes_bot}\")\n",
    "        print(f\"🎭 Personalidad actual: {self.personalidad_actual}\")\n",
    "        print(f\"📝 Total de mensajes: {len(self.historial)}\")\n",
    "        print(\"=\" * 25)\n",
    "    \n",
    "    def mostrar_historial(self):\n",
    "        \"\"\"Muestra el historial completo\"\"\"\n",
    "        if not self.historial:\n",
    "            print(\"\\n📝 No hay historial disponible\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== 📝 HISTORIAL COMPLETO ===\")\n",
    "        for i, mensaje in enumerate(self.historial, 1):\n",
    "            if isinstance(mensaje, HumanMessage):\n",
    "                print(f\"{i}. 🧑 Usuario: {mensaje.content}\")\n",
    "            elif isinstance(mensaje, AIMessage):\n",
    "                print(f\"{i}. 🤖 Bot: {mensaje.content[:100]}{'...' if len(mensaje.content) > 100 else ''}\")\n",
    "        print(\"=\" * 30)\n",
    "    \n",
    "    def procesar_comando(self, comando):\n",
    "        \"\"\"Procesa comandos especiales\"\"\"\n",
    "        partes = comando.split()\n",
    "        cmd = partes[0].lower()\n",
    "        \n",
    "        if cmd == \"/help\":\n",
    "            self.mostrar_ayuda()\n",
    "        elif cmd == \"/clear\":\n",
    "            self.limpiar_historial()\n",
    "        elif cmd == \"/personalidades\":\n",
    "            self.mostrar_personalidades()\n",
    "        elif cmd == \"/personalidad\":\n",
    "            if len(partes) > 1:\n",
    "                self.cambiar_personalidad(partes[1])\n",
    "            else:\n",
    "                print(\"\\n❌ Uso: /personalidad [nombre]\")\n",
    "                self.mostrar_personalidades()\n",
    "        elif cmd == \"/stats\":\n",
    "            self.mostrar_estadisticas()\n",
    "        elif cmd == \"/historial\":\n",
    "            self.mostrar_historial()\n",
    "        elif cmd == \"/salir\":\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"\\n❌ Comando desconocido: {comando}\")\n",
    "            print(\"💡 Usa /help para ver comandos disponibles\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def iniciar_chat(self):\n",
    "        \"\"\"Inicia el bucle principal del chatbot\"\"\"\n",
    "        print(\"🤖 === CHATBOT MEJORADO CON STREAMING ===\")\n",
    "        print(\"💡 Escribe /help para ver comandos disponibles\")\n",
    "        print(\"🎭 Personalidad inicial: asistente\")\n",
    "        print(\"-\" * 45)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Obtener input del usuario\n",
    "                user_input = input(\"\\n🧑 Tú: \").strip()\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                # Verificar si es un comando\n",
    "                if user_input.startswith('/'):\n",
    "                    if not self.procesar_comando(user_input):\n",
    "                        break\n",
    "                    continue\n",
    "                \n",
    "                # Agregar mensaje del usuario al historial\n",
    "                self.historial.append(HumanMessage(content=user_input))\n",
    "                \n",
    "                # Preparar mensajes para el modelo\n",
    "                system_msg = SystemMessage(content=self.personalidades[self.personalidad_actual])\n",
    "                messages = [system_msg] + self.historial\n",
    "                \n",
    "                print(f\"\\n🤖 Bot ({self.personalidad_actual}): \", end=\"\", flush=True)\n",
    "                \n",
    "                # Streaming de la respuesta\n",
    "                full_response = \"\"\n",
    "                for chunk in llm.stream(messages):\n",
    "                    content = chunk.content\n",
    "                    print(content, end=\"\", flush=True)\n",
    "                    full_response += content\n",
    "                    time.sleep(0.03)\n",
    "                \n",
    "                # Agregar respuesta del bot al historial\n",
    "                self.historial.append(AIMessage(content=full_response))\n",
    "                \n",
    "                print()  # Nueva línea\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\n⏸️ Conversación interrumpida\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n❌ Error: {e}\")\n",
    "        \n",
    "        print(\"\\n👋 ¡Hasta luego! Gracias por usar el chatbot.\")\n",
    "\n",
    "# Crear y ejecutar el chatbot\n",
    "chatbot = ChatbotMejorado()\n",
    "chatbot.iniciar_chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
