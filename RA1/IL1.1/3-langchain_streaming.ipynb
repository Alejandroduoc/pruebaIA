{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hfn0f7nyumn",
   "metadata": {},
   "source": [
    "# 3. LangChain Streaming - Respuestas en Tiempo Real\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender qu√© es el streaming y cu√°ndo usarlo\n",
    "- Implementar streaming con LangChain\n",
    "- Manejar chunks de datos en tiempo real\n",
    "- Construir interfaces de usuario reactivas\n",
    "\n",
    "## ¬øQu√© es el Streaming?\n",
    "\n",
    "El streaming permite recibir la respuesta del modelo **token por token** conforme se genera, en lugar de esperar a que termine completamente. Esto mejora significativamente la experiencia de usuario en aplicaciones interactivas.\n",
    "\n",
    "### Ventajas del Streaming:\n",
    "- **Percepci√≥n de velocidad**: El usuario ve progreso inmediato\n",
    "- **Mejor UX**: Interfaces m√°s reactivas e interactivas  \n",
    "- **Engagement**: Mantiene la atenci√≥n del usuario\n",
    "- **Debugging**: Permite ver el proceso de generaci√≥n\n",
    "\n",
    "### Casos de Uso Ideales:\n",
    "- Chatbots y asistentes conversacionales\n",
    "- Generaci√≥n de contenido largo\n",
    "- Aplicaciones web interactivas\n",
    "- Demostraciones en vivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa694f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas correctamente para streaming\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Bibliotecas importadas correctamente para streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13f037cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Modelo configurado con streaming habilitado\n",
      "Modelo: gpt-4o\n",
      "Streaming: True\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del modelo con streaming habilitado\n",
    "try:\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "         base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "         api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "         model=\"gpt-4o\",\n",
    "         streaming=True,  # ¬°Importante: habilitar streaming!\n",
    "         temperature=0.7\n",
    "     )\n",
    "    # llm = ChatOpenAI(\n",
    "    #     base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "    #     api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "    #     model = \"openai/gpt-4.1\",               # modelo DeepSeek\n",
    "    #     temperature=0.7,\n",
    "    #     streaming=True, \n",
    "    #     max_tokens=150\n",
    "    # )\n",
    "    \n",
    "    print(\"‚úì Modelo configurado con streaming habilitado\")\n",
    "    print(f\"Modelo: {llm.model_name}\")\n",
    "    print(f\"Streaming: {llm.streaming}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error en configuraci√≥n: {e}\")\n",
    "    print(\"Verifica las variables de entorno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da0d27",
   "metadata": {},
   "source": [
    "## Streaming B√°sico\n",
    "\n",
    "El m√©todo `.stream()` devuelve un generador que produce chunks de texto conforme se generan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1f31f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING EN TIEMPO REAL ===\n",
      "Generando respuesta...\n",
      "--------------------------------------------------\n",
      "‚úó Error en streaming: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 53609 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 53609 seconds before retrying.'}}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo b√°sico de streaming\n",
    "def streaming_basico():\n",
    "    prompt = \"Cu√©ntame una historia breve sobre los beneficios de el oregano \"\n",
    "    \n",
    "    print(\"=== STREAMING EN TIEMPO REAL ===\")\n",
    "    print(\"Generando respuesta...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # stream() devuelve un generador de chunks\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Imprimir cada chunk sin nueva l√≠nea\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.01)  # Peque√±a pausa para simular streaming visual\n",
    "            \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"‚úì Streaming completado\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error en streaming: {e}\")\n",
    "\n",
    "# Ejecutar streaming b√°sico\n",
    "streaming_basico()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10285d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1A: SPINNER SIMPLE ===\n",
      "Generando respuesta...\n",
      "\n",
      "‚úì Completado!   l or√©gano aporta beneficios antioxidantes, antimicrobianos y antiinflamatorios. Mejora la digesti√≥n, refuerza el sistema inmunol√≥gico, combate infecciones y contribuye a la salud respiratoria. Sus compuestos ayudan a prevenir enfermedades y promueven el bienestar general.\n",
      "\n",
      "Respuesta completa:\n",
      "El or√©gano aporta beneficios antioxidantes, antimicrobianos y antiinflamatorios. Mejora la digesti√≥n, refuerza el sistema inmunol√≥gico, combate infecciones y contribuye a la salud respiratoria. Sus compuestos ayudan a prevenir enfermedades y promueven el bienestar general.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "import re\n",
    "from itertools import cycle\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EJERCICIO 1: INDICADORES DE PROGRESO\n",
    "# =============================================================================\n",
    "\n",
    "def ejercicio1_spinner_simple():\n",
    "    \"\"\"Spinner b√°sico que rota mientras llegan chunks\"\"\"\n",
    "  \n",
    "    spinner = cycle(['|', '/', '-', '\\\\'])\n",
    "    prompt = \"rwsumido en 30 palabras :Explica los beneficios del oregano para la salud\"\n",
    "    \n",
    "    print(\"=== EJERCICIO 1A: SPINNER SIMPLE ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    \n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        \n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Mostrar spinner\n",
    "            sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            \n",
    "        # Limpiar spinner y mostrar resultado\n",
    "        sys.stdout.write('\\r‚úì Completado!   \\n')\n",
    "        print(f\"\\nRespuesta completa:\\n{response_text}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "ejercicio1_spinner_simple()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8852d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1A: SPINNER SIMPLE ===\n",
      "Generando respuesta...\n",
      "\n",
      "                    √©gano ofrece propiedades antioxidantes, antiinflamatorias y antimicrobianas. Favorece la digesti√≥n, fortalece el sistema inmunol√≥gico, protege contra infecciones y contribuye a la salud cardiovascular, gracias a sus compuestos como carvacrol y timol.\n",
      "‚úì Completado!\n",
      "\n",
      "Respuesta completa:\n",
      "El or√©gano ofrece propiedades antioxidantes, antiinflamatorias y antimicrobianas. Favorece la digesti√≥n, fortalece el sistema inmunol√≥gico, protege contra infecciones y contribuye a la salud cardiovascular, gracias a sus compuestos como carvacrol y timol.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#modificado \n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "from itertools import cycle\n",
    "\n",
    "def spinner_task(stop_event):\n",
    "    spinner = cycle(['|', '/', '-', '\\\\'])\n",
    "    while not stop_event.is_set():\n",
    "        sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.1)\n",
    "    sys.stdout.write('\\r' + ' ' * 20 + '\\r')  # limpia la l√≠nea del spinner\n",
    "\n",
    "def ejercicio1_spinner_simple():\n",
    "    prompt = \"resumen en 30 palabras :Explica los beneficios del oregano para la salud\"\n",
    "    print(\"=== EJERCICIO 1A: SPINNER SIMPLE ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    response_text = \"\"\n",
    "    stop_event = threading.Event()\n",
    "    spinner_thread = threading.Thread(target=spinner_task, args=(stop_event,))\n",
    "    spinner_thread.start()\n",
    "\n",
    "    try:\n",
    "        # Recibe e imprime chunks normalmente (sin spinner aqu√≠)\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "        stop_event.set()\n",
    "        spinner_thread.join()\n",
    "        print(\"\\n‚úì Completado!\")\n",
    "        print(f\"\\nRespuesta completa:\\n{response_text}\\n\")\n",
    "    except Exception as e:\n",
    "        stop_event.set()\n",
    "        spinner_thread.join()\n",
    "        print(f\"\\nError: {e}\")\n",
    "\n",
    "ejercicio1_spinner_simple()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2190b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1B: BARRA DE PROGRESO ===\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% (117 chars)\n",
      "\n",
      "\n",
      "Respuesta final:\n",
      "La fotos√≠ntesis es el proceso donde las plantas convierten luz solar, agua y di√≥xido de carbono en glucosa y ox√≠geno.\n",
      "\n",
      "‚úÖ Barra de progreso completada!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def ejercicio1_barra_progreso():\n",
    "    \"\"\"Barra de progreso visual basada en longitud de texto generado\"\"\"\n",
    "    \n",
    "    prompt = \"resume en 20 palabras:Describe el proceso de fotos√≠ntesis en las plantas\"\n",
    "    print(\"=== EJERCICIO 1B: BARRA DE PROGRESO ===\")\n",
    "    \n",
    "    response_text = \"\"\n",
    "    last_percent = 0\n",
    "    bar_length = 30\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Progreso estimado basado en cantidad de caracteres\n",
    "            total_estimate = 30  # puedes ajustar seg√∫n lo largo que esperas que sea la respuesta\n",
    "            progress = min(len(response_text) / total_estimate, 1.0)\n",
    "            \n",
    "            filled_length = int(bar_length * progress)\n",
    "            bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)\n",
    "            percent = int(progress * 100)\n",
    "            \n",
    "            # Solo actualizar si hay un cambio real en porcentaje\n",
    "            if percent != last_percent:\n",
    "                sys.stdout.write(f'\\r[{bar}] {percent}% ({len(response_text)} chars)')\n",
    "                sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "            \n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        # Completa la barra al final\n",
    "        sys.stdout.write('\\r[' + '‚ñà'*bar_length + '] 100% (' + str(len(response_text)) + ' chars)\\n')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        print(f\"\\n\\nRespuesta final:\\n{response_text}\\n\")\n",
    "        print(\"‚úÖ Barra de progreso completada!\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "\n",
    "ejercicio1_barra_progreso()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6214408",
   "metadata": {},
   "source": [
    "## Comparaci√≥n: Streaming vs No-Streaming\n",
    "\n",
    "Veamos la diferencia en experiencia de usuario entre ambos enfoques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db8e5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACI√ìN: STREAMING vs NO-STREAMING ===\\n\n",
      "1. SIN STREAMING:\n",
      "--------------------\n",
      "Esperando respuesta completa...\n",
      "\\n[Respuesta recibida despu√©s de 3.09 segundos]\n",
      "El or√©gano es una hierba arom√°tica que ofrece numerosos beneficios para la salud. Su potente contenido de antioxidantes ayuda a combatir el da√±o celular y a fortalecer el sistema inmunol√≥gico. Adem√°s, posee propiedades antimicrobianas que pueden ayudar a combatir infecciones bacterianas y f√∫ngicas. El or√©gano tambi√©n es conocido por sus efectos antiinflamatorios, lo que puede ser beneficioso para condiciones como la artritis. Su consumo puede favorecer la digesti√≥n, aliviando problemas gastrointestinales y promoviendo la salud intestinal. Asimismo, su aceite esencial contiene compuestos como el carvacrol y el timol, que han demostrado propiedades terap√©uticas. Incorporar or√©gano en la dieta no solo realza el sabor de los platillos, sino que tambi√©n contribuye al bienestar general, convirti√©ndolo en un aliado natural en la cocina y en la salud.\n",
      "\\n============================================================\\n\n",
      "2. CON STREAMING:\n",
      "------------------\n",
      "Respuesta en tiempo real:\n",
      "Error: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 53865 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 53865 seconds before retrying.'}}\n",
      "\\n============================================================\n",
      "OBSERVACIONES:\n",
      "- Sin streaming: El usuario espera sin feedback\n",
      "- Con streaming: El usuario ve progreso inmediato\n",
      "- Mejor percepci√≥n de velocidad con streaming\n",
      "- Streaming es especial para respuestas largas\n"
     ]
    }
   ],
   "source": [
    "# Comparaci√≥n entre streaming y no-streaming\n",
    "def comparar_streaming():\n",
    "\n",
    "    # Modelo sin streaming\n",
    "    llm_no_stream = ChatOpenAI(\n",
    "        base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "        #model = \"openai/gpt-4.1\",               \n",
    "        model = \"openai/gpt-4o-mini\",\n",
    "        temperature=0.7,\n",
    "        streaming=False  # Sin streaming\n",
    "       \n",
    "    )\n",
    "    \n",
    "    prompt = \"resumido en 150 palabras :Escribe un p√°rrafo sobre beneficions del oregano\"\n",
    "    \n",
    "    print(\"=== COMPARACI√ìN: STREAMING vs NO-STREAMING ===\\\\n\")\n",
    "    \n",
    "    # 1. Sin streaming\n",
    "    print(\"1. SIN STREAMING:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Esperando respuesta completa...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = llm_no_stream.invoke([HumanMessage(content=prompt)])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\\\n[Respuesta recibida despu√©s de {end_time - start_time:.2f} segundos]\")\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60 + \"\\\\n\")\n",
    "    \n",
    "    # 2. Con streaming\n",
    "    print(\"2. CON STREAMING:\")\n",
    "    print(\"-\" * 18)\n",
    "    print(\"Respuesta en tiempo real:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.03)  # Simular pausa para efecto visual\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\\\n\\\\n[Streaming completado en {end_time - start_time:.2f} segundos]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"OBSERVACIONES:\")\n",
    "    print(\"- Sin streaming: El usuario espera sin feedback\")\n",
    "    print(\"- Con streaming: El usuario ve progreso inmediato\")\n",
    "    print(\"- Mejor percepci√≥n de velocidad con streaming\")\n",
    "    print(\"- Streaming es especial para respuestas largas\")\n",
    "\n",
    "# Ejecutar comparaci√≥n\n",
    "comparar_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ad79d",
   "metadata": {},
   "source": [
    "## Implementaci√≥n de un Chatbot Simple con Streaming\n",
    "\n",
    "Creemos un chatbot b√°sico que demuestre el streaming en un contexto pr√°ctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot simple con streaming\n",
    "def chatbot_streaming():\n",
    "    print(\"=== CHATBOT CON STREAMING ===\")\n",
    "    print(\"Escribe 'salir' para terminar la conversaci√≥n\\\\n\")\n",
    "    \n",
    "    # Configurar asistente con personalidad\n",
    "    system_message = \"\"\"Eres un asistente √∫til y amigable especializado en tecnolog√≠a. \n",
    "    Respondes de manera clara y concisa, y siempre intentas ser educativo.\"\"\"\n",
    "    \n",
    "    while True:\n",
    "        # Obtener input del usuario\n",
    "        user_input = input(\"\\\\nüßë T√∫: \")\n",
    "        \n",
    "        if user_input.lower() in ['salir', 'exit', 'quit']:\n",
    "            print(\"\\\\nüëã ¬°Hasta luego!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input.strip():\n",
    "            continue\n",
    "            \n",
    "        print(\"\\\\nü§ñ Asistente: \", end=\"\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Streaming de la respuesta\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "            \n",
    "            # Convertir a formato LangChain\n",
    "            from langchain.schema import SystemMessage\n",
    "            lc_messages = [\n",
    "                SystemMessage(content=system_message),\n",
    "                HumanMessage(content=user_input)\n",
    "            ]\n",
    "            \n",
    "            full_response = \"\"\n",
    "            for chunk in llm.stream(lc_messages):\n",
    "                content = chunk.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "                time.sleep(0.02)\n",
    "                \n",
    "            print()  # Nueva l√≠nea al final\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\\\n\\\\n‚è∏Ô∏è Interrumpido por el usuario\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n‚ùå Error: {e}\")\n",
    "            \n",
    "    print(\"\\\\n¬°Gracias por usar el chatbot!\")\n",
    "\n",
    "# Ejecutar chatbot (¬°Pru√©balo!)\n",
    "chatbot_streaming() \n",
    " # Descomenta esta l√≠nea para ejecutar\n",
    "\n",
    "print(\"üí° Descomenta la l√≠nea anterior para probar el chatbot interactivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060e43c",
   "metadata": {},
   "source": [
    "## Streaming Avanzado con Manejo de Chunks\n",
    "\n",
    "Podemos procesar cada chunk individualmente para crear experiencias m√°s sofisticadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fa1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming con an√°lisis de chunks\n",
    "def streaming_avanzado():\n",
    "    prompt = \"Explica qu√© es la inteligencia artificial y c√≥mo funciona el machine learning\"\n",
    "    \n",
    "    print(\"=== STREAMING AVANZADO CON AN√ÅLISIS ===\")\n",
    "    print(\"Analizando chunks conforme llegan...\\n\")\n",
    "    \n",
    "    # Variables para estad√≠sticas\n",
    "    chunk_count = 0\n",
    "    total_content = \"\"\n",
    "    words_processed = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            chunk_count += 1\n",
    "            content = chunk.content\n",
    "            total_content += content\n",
    "            \n",
    "            # Contar palabras aproximadas\n",
    "            if content.strip():\n",
    "                words_in_chunk = len(content.split())\n",
    "                words_processed += words_in_chunk\n",
    "            \n",
    "            # Mostrar progreso cada 10 chunks\n",
    "            if chunk_count % 10 == 0:\n",
    "                print(f\"\\\\n[Progreso: {chunk_count} chunks, ~{words_processed} palabras]\\\\n\")\n",
    "            \n",
    "            # Imprimir el contenido\n",
    "            print(content, end=\"\", flush=True)\n",
    "            time.sleep(0.02)  # Pausa ligeramente m√°s larga para ver el an√°lisis\n",
    "        \n",
    "        # Estad√≠sticas finales\n",
    "        print(f\"\\\\n\\\\n=== ESTAD√çSTICAS FINALES ===\")\n",
    "        print(f\"Total de chunks: {chunk_count}\")\n",
    "        print(f\"Palabras aproximadas: {words_processed}\")\n",
    "        print(f\"Caracteres totales: {len(total_content)}\")\n",
    "        print(f\"Promedio chars/chunk: {len(total_content)/chunk_count if chunk_count > 0 else 0:.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\n‚úó Error: {e}\")\n",
    "\n",
    "# Ejecutar streaming avanzado\n",
    "streaming_avanzado()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac251a9d",
   "metadata": {},
   "source": [
    "## Consideraciones T√©cnicas del Streaming\n",
    "\n",
    "### Cu√°ndo Usar Streaming:\n",
    "‚úÖ **S√ç usar streaming:**\n",
    "- Respuestas largas (>100 tokens)\n",
    "- Aplicaciones interactivas\n",
    "- Chatbots y asistentes\n",
    "- Demostraciones en vivo\n",
    "- Cuando la UX es prioritaria\n",
    "\n",
    "‚ùå **NO usar streaming:**\n",
    "- Respuestas muy cortas\n",
    "- Procesamiento batch\n",
    "- APIs de backend sin interfaz\n",
    "- Cuando necesitas la respuesta completa antes de procesar\n",
    "\n",
    "### Mejores Pr√°cticas:\n",
    "1. **Manejo de errores**: Siempre incluye try/catch\n",
    "2. **Indicadores visuales**: Muestra progreso al usuario\n",
    "3. **Cancelaci√≥n**: Permite al usuario interrumpir\n",
    "4. **Buffer management**: Para interfaces web, considera buffering\n",
    "5. **Performance**: Monitorea el uso de recursos\n",
    "\n",
    "## Ejercicios Pr√°cticos\n",
    "\n",
    "### Ejercicio 1: Indicador de Progreso\n",
    "Modifica el c√≥digo para mostrar un indicador de progreso (spinner, barra, porcentaje).\n",
    "\n",
    "### Ejercicio 2: Streaming con Filtros\n",
    "Implementa streaming que filtre o procese chunks espec√≠ficos (ej: resaltar palabras clave).\n",
    "\n",
    "### Ejercicio 3: Chatbot Mejorado\n",
    "Extiende el chatbot con:\n",
    "- Historial de conversaci√≥n\n",
    "- Comandos especiales (/help, /clear)\n",
    "- Diferentes personalidades\n",
    "\n",
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Streaming** mejora la percepci√≥n de velocidad\n",
    "2. **Chunks** se procesan individualmente en tiempo real\n",
    "3. **UX** es significativamente mejor con streaming\n",
    "4. **Implementaci√≥n** requiere manejo cuidadoso de generadores\n",
    "5. **Casos de uso** espec√≠ficos donde streaming aporta valor\n",
    "\n",
    "## Pr√≥ximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos la **memoria en LangChain**, que nos permite mantener contexto entre m√∫ltiples interacciones del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced2c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando respuesta...\n",
      "‚úÖ Completado!        \n",
      "\n",
      "**Python** es un **lenguaje de programaci√≥n** de alto nivel, interpretado, multiparadigma (soporta programaci√≥n orientada a objetos, imperativa y funcional), y de prop√≥sito general. Fue creado por **Guido van Rossum** y publicado en 1991. Su dise√±o enfatiza la legibilidad del c√≥digo y una sintaxis sencilla que permite a los programadores expresar conceptos en menos l√≠neas de c√≥digo que otros lenguajes.\n",
      "\n",
      "### Ventajas de Python\n",
      "\n",
      "1. **Sintaxis sencilla y legible**  \n",
      "   Python est√° dise√±ado para ser f√°cil de leer y escribir, lo que facilita el aprendizaje y el desarrollo r√°pido.\n",
      "\n",
      "2. **Gran comunidad y soporte**  \n",
      "   Cuenta con una comunidad activa que aporta miles de librer√≠as\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#import time\n",
    "from itertools import cycle\n",
    "#from langchain_openai import ChatOpenAI\n",
    "#from langchain.schema import HumanMessage\n",
    "\n",
    "def spinner_progreso():\n",
    "    \"\"\"Spinner que rota mientras llegan los chunks\"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Caracteres del spinner\n",
    "    spinner = cycle(['‚†ã', '‚†ô', '‚†π', '‚†∏', '‚†º', '‚†¥', '‚†¶', '‚†ß', '‚†á', '‚†è'])\n",
    "    \n",
    "    prompt = \"Explica qu√© es Python y sus ventajas\"\n",
    "    response_text = \"\"\n",
    "    \n",
    "    print(\"Generando respuesta...\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Mostrar spinner\n",
    "            sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        # Limpiar spinner y mostrar resultado\n",
    "        sys.stdout.write('\\r‚úÖ Completado!        \\n\\n')\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "spinner_progreso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b67c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Barra de Progreso ===\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% (617 chars)\n",
      "\n",
      "Respuesta completa:\n",
      "Claro, aqu√≠ tienes una descripci√≥n paso a paso del proceso de **machine learning** (aprendizaje autom√°tico):\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Definici√≥n del problema**\n",
      "   - Identifica y comprende el problema que deseas resolver.\n",
      "   - Ejemplo: ¬øQuieres clasificar correos como spam/no spam?\n",
      "\n",
      "### 2. **Recolecci√≥n de datos**\n",
      "   - Obt√©n datos relevantes para el problema.\n",
      "   - Pueden provenir de bases de datos, sensores, web, etc.\n",
      "\n",
      "### 3. **Preprocesamiento de datos**\n",
      "   - Limpieza: Elimina duplicados, corrige errores y trata valores faltantes.\n",
      "   - Transformaci√≥n: Normaliza o estandariza datos, convierte variables categ√≥ricas en num\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "def barra_progreso():\n",
    "    \"\"\"Barra de progreso basada en caracteres generados\"\"\"\n",
    "    \n",
    "    prompt = \"Describe el proceso de machine learning paso a paso\"\n",
    "    response_text = \"\"\n",
    "    bar_length = 25\n",
    "    estimated_total = 400  # Estimaci√≥n de caracteres esperados\n",
    "    \n",
    "    print(\"=== Barra de Progreso ===\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Calcular progreso\n",
    "            progress = min(len(response_text) / estimated_total, 1.0)\n",
    "            filled = int(bar_length * progress)\n",
    "            \n",
    "            # Crear barra visual\n",
    "            bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)\n",
    "            percent = int(progress * 100)\n",
    "            \n",
    "            # Actualizar barra\n",
    "            sys.stdout.write(f'\\r[{bar}] {percent}% ({len(response_text)} chars)')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        # Completar al 100%\n",
    "        sys.stdout.write(f'\\r[{\"‚ñà\" * bar_length}] 100% ({len(response_text)} chars)\\n\\n')\n",
    "        print(\"Respuesta completa:\")\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "barra_progreso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6143ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Contador de Palabras ===\n",
      "Generando respuesta...\n",
      "\n",
      "üìù Palabras: 103 | Caracteres: 727\n",
      "\n",
      "‚úÖ Generaci√≥n completada!\n",
      "üìä Estad√≠sticas finales: 103 palabras, 727 caracteres\n",
      "\n",
      "Respuesta:\n",
      "La inteligencia artificial (IA) ofrece numerosos beneficios en diferentes √°mbitos de la vida y sectores productivos. Algunos de los principales son:\n",
      "\n",
      "1. **Automatizaci√≥n de tareas**: Permite que procesos repetitivos o complejos se realicen de forma autom√°tica, ahorrando tiempo y reduciendo errores humanos.\n",
      "\n",
      "2. **Mejora en la toma de decisiones**: La IA puede analizar grandes cantidades de datos y ofrecer recomendaciones o predicciones m√°s precisas que las realizadas manualmente.\n",
      "\n",
      "3. **Personalizaci√≥n**: En √°reas como el comercio electr√≥nico, la educaci√≥n y la salud, la IA puede adaptar productos, servicios o contenidos a las necesidades y preferencias individuales de los usuarios.\n",
      "\n",
      "4. **Eficiencia operativa**: Ayuda a\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def contador_palabras():\n",
    "    \"\"\"Muestra el conteo de palabras conforme se genera el texto\"\"\"\n",
    "    \n",
    "    prompt = \"Cu√©ntame sobre los beneficios de la inteligencia artificial\"\n",
    "    response_text = \"\"\n",
    "    \n",
    "    print(\"=== Contador de Palabras ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Contar palabras\n",
    "            words = len(re.findall(r'\\b\\w+\\b', response_text))\n",
    "            chars = len(response_text)\n",
    "            \n",
    "            # Mostrar progreso\n",
    "            sys.stdout.write(f'\\rüìù Palabras: {words} | Caracteres: {chars}')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(f\"\\n\\n‚úÖ Generaci√≥n completada!\")\n",
    "        print(f\"üìä Estad√≠sticas finales: {words} palabras, {chars} caracteres\\n\")\n",
    "        print(\"Respuesta:\")\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "contador_palabras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4604485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING CON RESALTADO DE PALABRAS CLAVE ===\n",
      "üîç Palabras clave: python, machine learning, inteligencia artificial, algoritmo, datos, modelo\n",
      "\n",
      "Respuesta (palabras clave resaltadas con *):\n",
      "--------------------------------------------------\n",
      "***PYTHON*** es un lenguaje de programaci√≥n de alto nivel, de prop√≥sito general, que se caracteriza por ser sencillo, legible y f√°cil de aprender. Fue creado a finales de los a√±os 80 y desde entonces ha ganado enorme popularidad, especialmente en √°reas como ciencia de *DATOS*, desarrollo web, automatizaci√≥n y, de manera destacada, en **machine learning (aprendizaje autom√°tico)** e **inteligencia artificial (IA)**.\n",
      "\n",
      "### ¬øQu√© es *PYTHON*?\n",
      "\n",
      "- **Sintaxis clara y sencilla**, lo que facilita el desarrollo y mantenimiento de c√≥digo.\n",
      "- Es **multiparadigma**, permitiendo programaci√≥n orientada a objetos, imperativa y funcional.\n",
      "- Posee una **gran comunidad** y una **amplia colecci√≥n de bibliotecas\n",
      "--------------------------------------------------\n",
      "‚úÖ Streaming completado!\n",
      "üéØ Palabras clave resaltadas: 3\n"
     ]
    }
   ],
   "source": [
    "def streaming_con_resaltado():\n",
    "    \"\"\"Resalta palabras clave espec√≠ficas durante el streaming\"\"\"\n",
    "    \n",
    "    # Palabras clave a resaltar\n",
    "    keywords = [\"python\", \"machine learning\", \"inteligencia artificial\", \"algoritmo\", \"datos\", \"modelo\"]\n",
    "    \n",
    "    prompt = \"Explica qu√© es Python y c√≥mo se usa en machine learning e inteligencia artificial\"\n",
    "    \n",
    "    print(\"=== STREAMING CON RESALTADO DE PALABRAS CLAVE ===\")\n",
    "    print(f\"üîç Palabras clave: {', '.join(keywords)}\\n\")\n",
    "    print(\"Respuesta (palabras clave resaltadas con *):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response_text = \"\"\n",
    "    highlighted_count = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            content = chunk.content\n",
    "            response_text += content\n",
    "            \n",
    "            # Procesar cada chunk para resaltar palabras clave\n",
    "            processed_content = content\n",
    "            for keyword in keywords:\n",
    "                # Buscar la palabra clave (insensible a may√∫sculas/min√∫sculas)\n",
    "                pattern = re.compile(re.escape(keyword), re.IGNORECASE)\n",
    "                if pattern.search(processed_content):\n",
    "                    processed_content = pattern.sub(f\"*{keyword.upper()}*\", processed_content)\n",
    "                    highlighted_count += 1\n",
    "            \n",
    "            # Mostrar el chunk procesado\n",
    "            print(processed_content, end=\"\", flush=True)\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(f\"\\n{'-' * 50}\")\n",
    "        print(f\"‚úÖ Streaming completado!\")\n",
    "        print(f\"üéØ Palabras clave resaltadas: {highlighted_count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "streaming_con_resaltado()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c68777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas importadas correctamente con SystemMessage\n",
      "ü§ñ === CHATBOT MEJORADO CON STREAMING ===\n",
      "üí° Escribe /help para ver comandos disponibles\n",
      "üé≠ Personalidad inicial: asistente\n",
      "---------------------------------------------\n",
      "\n",
      "ü§ñ Bot (asistente): ¬°Hola! ¬øEn qu√© puedo ayudarte hoy?\n",
      "\n",
      "‚ùå Uso: /personalidad [nombre]\n",
      "\n",
      "=== üé≠ PERSONALIDADES DISPONIBLES ===\n",
      "‚û§ asistente: Eres un asistente √∫til y profesional. Respondes de manera clara y concisa.\n",
      "   amigable: Eres muy amigable y casual. Usas emojis y un tono relajado. üòä\n",
      "   tecnico: Eres un experto t√©cnico. Das respuestas detalladas y precisas con terminolog√≠a espec√≠fica.\n",
      "   creativo: Eres muy creativo e imaginativo. Usas met√°foras y ejemplos √∫nicos.\n",
      "   profesor: Eres un profesor paciente. Explicas paso a paso y das ejemplos educativos.\n",
      "========================================\n",
      "\n",
      "ü§ñ Bot (asistente): ¬°Hola de nuevo! ¬øC√≥mo puedo ayudarte?\n",
      "\n",
      "ü§ñ Bot (asistente): Soy un asistente virtual creado para ayudarte. No tengo un nombre propio, pero puedes llamarme simplemente \"Asistente\". ¬øEn qu√© puedo ayudarte hoy?\n",
      "\n",
      "ü§ñ Bot (asistente): Me llamo Asistente. Estoy aqu√≠ para ayudarte con cualquier pregunta o tarea que tengas. ¬øEn qu√© puedo ayudarte hoy?\n",
      "\n",
      "ü§ñ Bot (asistente): Un beneficio del or√©gano es que tiene propiedades antioxidantes, lo que ayuda a proteger las c√©lulas del cuerpo contra el da√±o causado por los radicales libres.\n",
      "\n",
      "ü§ñ Bot (asistente): Un beneficio del or√©gano es que ayuda a fortalecer el sistema inmunol√≥gico gracias a sus compuestos antimicrobianos y antiinflamatorios.\n",
      "\n",
      "ü§ñ Bot (asistente): ¬°Perfecto! Si necesitas ayuda en el futuro, aqu√≠ estar√©. ¬°Hasta luego!\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ IMPORTACIONES CORREGIDAS\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "from itertools import cycle\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage  # ‚Üê Aqu√≠ estaba el problema\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas correctamente con SystemMessage\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ChatbotMejorado:\n",
    "    def __init__(self):\n",
    "        self.historial = []\n",
    "        self.personalidad_actual = \"asistente\"\n",
    "        self.personalidades = {\n",
    "            \"asistente\": \"Eres un asistente √∫til y profesional. Respondes de manera clara y concisa.\",\n",
    "            \"amigable\": \"Eres muy amigable y casual. Usas emojis y un tono relajado. üòä\",\n",
    "            \"tecnico\": \"Eres un experto t√©cnico. Das respuestas detalladas y precisas con terminolog√≠a espec√≠fica.\",\n",
    "            \"creativo\": \"Eres muy creativo e imaginativo. Usas met√°foras y ejemplos √∫nicos.\",\n",
    "            \"profesor\": \"Eres un profesor paciente. Explicas paso a paso y das ejemplos educativos.\"\n",
    "        }\n",
    "    \n",
    "    def mostrar_ayuda(self):\n",
    "        \"\"\"Muestra los comandos disponibles\"\"\"\n",
    "        print(\"\\n=== üìã COMANDOS DISPONIBLES ===\")\n",
    "        print(\"üîß /help - Muestra esta ayuda\")\n",
    "        print(\"üóëÔ∏è  /clear - Limpia el historial\")\n",
    "        print(\"üë§ /personalidad [nombre] - Cambia personalidad\")\n",
    "        print(\"üìù /personalidades - Lista personalidades disponibles\") \n",
    "        print(\"üìä /stats - Muestra estad√≠sticas de la conversaci√≥n\")\n",
    "        print(\"üíæ /historial - Muestra historial completo\")\n",
    "        print(\"üö™ /salir - Termina la conversaci√≥n\")\n",
    "        print(\"=\" * 35)\n",
    "    \n",
    "    def mostrar_personalidades(self):\n",
    "        \"\"\"Lista las personalidades disponibles\"\"\"\n",
    "        print(\"\\n=== üé≠ PERSONALIDADES DISPONIBLES ===\")\n",
    "        for nombre, descripcion in self.personalidades.items():\n",
    "            marca = \"‚û§\" if nombre == self.personalidad_actual else \"  \"\n",
    "            print(f\"{marca} {nombre}: {descripcion}\")\n",
    "        print(\"=\" * 40)\n",
    "    \n",
    "    def cambiar_personalidad(self, nueva_personalidad):\n",
    "        \"\"\"Cambia la personalidad del chatbot\"\"\"\n",
    "        if nueva_personalidad in self.personalidades:\n",
    "            self.personalidad_actual = nueva_personalidad\n",
    "            print(f\"\\n‚úÖ Personalidad cambiada a: {nueva_personalidad}\")\n",
    "            print(f\"üìù {self.personalidades[nueva_personalidad]}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Personalidad '{nueva_personalidad}' no encontrada\")\n",
    "            self.mostrar_personalidades()\n",
    "    \n",
    "    def limpiar_historial(self):\n",
    "        \"\"\"Limpia el historial de conversaci√≥n\"\"\"\n",
    "        self.historial = []\n",
    "        print(\"\\nüóëÔ∏è Historial limpiado correctamente\")\n",
    "    \n",
    "    def mostrar_estadisticas(self):\n",
    "        \"\"\"Muestra estad√≠sticas de la conversaci√≥n\"\"\"\n",
    "        if not self.historial:\n",
    "            print(\"\\nüìä No hay estad√≠sticas disponibles (historial vac√≠o)\")\n",
    "            return\n",
    "        \n",
    "        mensajes_usuario = sum(1 for msg in self.historial if isinstance(msg, HumanMessage))\n",
    "        mensajes_bot = sum(1 for msg in self.historial if isinstance(msg, AIMessage))\n",
    "        \n",
    "        print(f\"\\n=== üìä ESTAD√çSTICAS ===\")\n",
    "        print(f\"üí¨ Mensajes del usuario: {mensajes_usuario}\")\n",
    "        print(f\"ü§ñ Respuestas del bot: {mensajes_bot}\")\n",
    "        print(f\"üé≠ Personalidad actual: {self.personalidad_actual}\")\n",
    "        print(f\"üìù Total de mensajes: {len(self.historial)}\")\n",
    "        print(\"=\" * 25)\n",
    "    \n",
    "    def mostrar_historial(self):\n",
    "        \"\"\"Muestra el historial completo\"\"\"\n",
    "        if not self.historial:\n",
    "            print(\"\\nüìù No hay historial disponible\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== üìù HISTORIAL COMPLETO ===\")\n",
    "        for i, mensaje in enumerate(self.historial, 1):\n",
    "            if isinstance(mensaje, HumanMessage):\n",
    "                print(f\"{i}. üßë Usuario: {mensaje.content}\")\n",
    "            elif isinstance(mensaje, AIMessage):\n",
    "                print(f\"{i}. ü§ñ Bot: {mensaje.content[:100]}{'...' if len(mensaje.content) > 100 else ''}\")\n",
    "        print(\"=\" * 30)\n",
    "    \n",
    "    def procesar_comando(self, comando):\n",
    "        \"\"\"Procesa comandos especiales\"\"\"\n",
    "        partes = comando.split()\n",
    "        cmd = partes[0].lower()\n",
    "        \n",
    "        if cmd == \"/help\":\n",
    "            self.mostrar_ayuda()\n",
    "        elif cmd == \"/clear\":\n",
    "            self.limpiar_historial()\n",
    "        elif cmd == \"/personalidades\":\n",
    "            self.mostrar_personalidades()\n",
    "        elif cmd == \"/personalidad\":\n",
    "            if len(partes) > 1:\n",
    "                self.cambiar_personalidad(partes[1])\n",
    "            else:\n",
    "                print(\"\\n‚ùå Uso: /personalidad [nombre]\")\n",
    "                self.mostrar_personalidades()\n",
    "        elif cmd == \"/stats\":\n",
    "            self.mostrar_estadisticas()\n",
    "        elif cmd == \"/historial\":\n",
    "            self.mostrar_historial()\n",
    "        elif cmd == \"/salir\":\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Comando desconocido: {comando}\")\n",
    "            print(\"üí° Usa /help para ver comandos disponibles\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def iniciar_chat(self):\n",
    "        \"\"\"Inicia el bucle principal del chatbot\"\"\"\n",
    "        print(\"ü§ñ === CHATBOT MEJORADO CON STREAMING ===\")\n",
    "        print(\"üí° Escribe /help para ver comandos disponibles\")\n",
    "        print(\"üé≠ Personalidad inicial: asistente\")\n",
    "        print(\"-\" * 45)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Obtener input del usuario\n",
    "                user_input = input(\"\\nüßë T√∫: \").strip()\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                # Verificar si es un comando\n",
    "                if user_input.startswith('/'):\n",
    "                    if not self.procesar_comando(user_input):\n",
    "                        break\n",
    "                    continue\n",
    "                \n",
    "                # Agregar mensaje del usuario al historial\n",
    "                self.historial.append(HumanMessage(content=user_input))\n",
    "                \n",
    "                # Preparar mensajes para el modelo\n",
    "                system_msg = SystemMessage(content=self.personalidades[self.personalidad_actual])\n",
    "                messages = [system_msg] + self.historial\n",
    "                \n",
    "                print(f\"\\nü§ñ Bot ({self.personalidad_actual}): \", end=\"\", flush=True)\n",
    "                \n",
    "                # Streaming de la respuesta\n",
    "                full_response = \"\"\n",
    "                for chunk in llm.stream(messages):\n",
    "                    content = chunk.content\n",
    "                    print(content, end=\"\", flush=True)\n",
    "                    full_response += content\n",
    "                    time.sleep(0.03)\n",
    "                \n",
    "                # Agregar respuesta del bot al historial\n",
    "                self.historial.append(AIMessage(content=full_response))\n",
    "                \n",
    "                print()  # Nueva l√≠nea\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\n‚è∏Ô∏è Conversaci√≥n interrumpida\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå Error: {e}\")\n",
    "        \n",
    "        print(\"\\nüëã ¬°Hasta luego! Gracias por usar el chatbot.\")\n",
    "\n",
    "# Crear y ejecutar el chatbot\n",
    "chatbot = ChatbotMejorado()\n",
    "chatbot.iniciar_chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
