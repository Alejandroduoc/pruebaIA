{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hfn0f7nyumn",
   "metadata": {},
   "source": [
    "# 3. LangChain Streaming - Respuestas en Tiempo Real\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender qué es el streaming y cuándo usarlo\n",
    "- Implementar streaming con LangChain\n",
    "- Manejar chunks de datos en tiempo real\n",
    "- Construir interfaces de usuario reactivas\n",
    "\n",
    "## ¿Qué es el Streaming?\n",
    "\n",
    "El streaming permite recibir la respuesta del modelo **token por token** conforme se genera, en lugar de esperar a que termine completamente. Esto mejora significativamente la experiencia de usuario en aplicaciones interactivas.\n",
    "\n",
    "### Ventajas del Streaming:\n",
    "- **Percepción de velocidad**: El usuario ve progreso inmediato\n",
    "- **Mejor UX**: Interfaces más reactivas e interactivas  \n",
    "- **Engagement**: Mantiene la atención del usuario\n",
    "- **Debugging**: Permite ver el proceso de generación\n",
    "\n",
    "### Casos de Uso Ideales:\n",
    "- Chatbots y asistentes conversacionales\n",
    "- Generación de contenido largo\n",
    "- Aplicaciones web interactivas\n",
    "- Demostraciones en vivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa694f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas correctamente para streaming\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Bibliotecas importadas correctamente para streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f037cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo configurado con streaming habilitado\n",
      "Modelo: openai/gpt-4o-mini\n",
      "Streaming: True\n"
     ]
    }
   ],
   "source": [
    "# Configuración del modelo con streaming habilitado\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "        model = \"openai/gpt-4o-mini\",               \n",
    "        temperature=0.7,\n",
    "        streaming=True  # Sin streaming\n",
    "       \n",
    "    )\n",
    "    # llm = ChatOpenAI(\n",
    "    #      base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    #      api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "    #      model=\"gpt-4o\",\n",
    "    #      streaming=True,  # ¡Importante: habilitar streaming!\n",
    "    #      temperature=0.7\n",
    "    #  )\n",
    "    # llm = ChatOpenAI(\n",
    "    #     base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "    #     api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "    #     model = \"openai/gpt-4.1\",               # modelo DeepSeek\n",
    "    #     temperature=0.7,\n",
    "    #     streaming=True, \n",
    "    #     max_tokens=150\n",
    "    # )\n",
    "    \n",
    "    print(\"✓ Modelo configurado con streaming habilitado\")\n",
    "    print(f\"Modelo: {llm.model_name}\")\n",
    "    print(f\"Streaming: {llm.streaming}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error en configuración: {e}\")\n",
    "    print(\"Verifica las variables de entorno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da0d27",
   "metadata": {},
   "source": [
    "## Streaming Básico\n",
    "\n",
    "El método `.stream()` devuelve un generador que produce chunks de texto conforme se generan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f31f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING EN TIEMPO REAL ===\n",
      "Generando respuesta...\n",
      "--------------------------------------------------\n",
      "Había una vez en un pequeño pueblo llamado Herbalia, donde los habitantes eran conocidos por su amor a las plantas y las especias. En el centro del pueblo, había una hermosa huerta que siempre estaba llena de aromas y colores. Entre todas las hierbas que allí crecían, el orégano era la estrella. \n",
      "\n",
      "Doña Clara, la sabia herbolaria del pueblo, siempre decía: “El orégano no solo da sabor a nuestros platillos, sino que también trae consigo muchos beneficios”. Un día, un grupo de niños curiosos se acercó a ella y le preguntó qué hacía tan especial a esta hierba.\n",
      "\n",
      "Doña Clara sonrió y comenzó a contarles sobre las maravillas del orégano. “Primero”, dijo, “es un gran aliado para nuestra salud. Tiene propiedades antioxidantes que ayudan a combatir los radicales libres y a mantener nuestro cuerpo joven y fuerte. Además, es un excelente antiinflamatorio, perfecto para aliviar esos pequeños dolores que todos sentimos de vez en cuando”.\n",
      "\n",
      "Los niños escuchaban fascinados mientras Doña Clara continuaba: “Pero eso no es todo. El orégano también es un gran amigo del sistema digestivo. Si te sientes un poco mal después de comer, una infusión de orégano puede ayudarte a sentirte mejor. Y en la cocina, su sabor realza cualquier plato, desde una simple salsa de tomate hasta una deliciosa pizza”.\n",
      "\n",
      "Intrigados, los niños decidieron ayudar a Doña Clara a cosechar un poco de orégano. Mientras trabajaban juntos, ella les enseñó a preparar una infusión y a usarlo en sus comidas. Pronto, todos en el pueblo comenzaron a notar los beneficios del orégano en su salud y en sus recetas.\n",
      "\n",
      "Con el tiempo, Herbalia se convirtió en un lugar famoso no solo por su encantadora huerta, sino también por la sabiduría de sus habitantes en el uso de las plantas. Y así, los niños aprendieron que, aunque el orégano era una simple hierba, tenía el poder de unir a la comunidad y mejorar la vida de todos.\n",
      "\n",
      "Desde entonces, el orégano se convirtió en un símbolo de salud y bienestar en Herbalia, y la historia de sus beneficios se transmitió de generación en generación, recordando a todos que a veces las soluciones más sencillas provienen de la naturaleza misma. Fin.\n",
      "--------------------------------------------------\n",
      "✓ Streaming completado\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo básico de streaming\n",
    "def streaming_basico():\n",
    "    prompt = \"Cuéntame una historia breve sobre los beneficios de el oregano \"\n",
    "    \n",
    "    print(\"=== STREAMING EN TIEMPO REAL ===\")\n",
    "    print(\"Generando respuesta...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # stream() devuelve un generador de chunks\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Imprimir cada chunk sin nueva línea\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.01)  # Pequeña pausa para simular streaming visual\n",
    "            \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"✓ Streaming completado\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error en streaming: {e}\")\n",
    "\n",
    "# Ejecutar streaming básico\n",
    "streaming_basico()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10285d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1A: SPINNER SIMPLE ===\n",
      "Generando respuesta...\n",
      "\n",
      "✓ Completado!   l orégano aporta beneficios antioxidantes, antimicrobianos y antiinflamatorios. Mejora la digestión, refuerza el sistema inmunológico, combate infecciones y contribuye a la salud respiratoria. Sus compuestos ayudan a prevenir enfermedades y promueven el bienestar general.\n",
      "\n",
      "Respuesta completa:\n",
      "El orégano aporta beneficios antioxidantes, antimicrobianos y antiinflamatorios. Mejora la digestión, refuerza el sistema inmunológico, combate infecciones y contribuye a la salud respiratoria. Sus compuestos ayudan a prevenir enfermedades y promueven el bienestar general.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "import re\n",
    "from itertools import cycle\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EJERCICIO 1: INDICADORES DE PROGRESO\n",
    "# =============================================================================\n",
    "\n",
    "def ejercicio1_spinner_simple():\n",
    "    \"\"\"Spinner básico que rota mientras llegan chunks\"\"\"\n",
    "  \n",
    "    spinner = cycle(['|', '/', '-', '\\\\'])\n",
    "    prompt = \"rwsumido en 30 palabras :Explica los beneficios del oregano para la salud\"\n",
    "    \n",
    "    print(\"=== EJERCICIO 1A: SPINNER SIMPLE ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    \n",
    "    response_text = \"\"\n",
    "    try:\n",
    "        \n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Mostrar spinner\n",
    "            sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            \n",
    "        # Limpiar spinner y mostrar resultado\n",
    "        sys.stdout.write('\\r✓ Completado!   \\n')\n",
    "        print(f\"\\nRespuesta completa:\\n{response_text}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "ejercicio1_spinner_simple()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8852d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1A: SPINNER SIMPLE ===\n",
      "Generando respuesta...\n",
      "\n",
      "                    égano ofrece propiedades antioxidantes, antiinflamatorias y antimicrobianas. Favorece la digestión, fortalece el sistema inmunológico, protege contra infecciones y contribuye a la salud cardiovascular, gracias a sus compuestos como carvacrol y timol.\n",
      "✓ Completado!\n",
      "\n",
      "Respuesta completa:\n",
      "El orégano ofrece propiedades antioxidantes, antiinflamatorias y antimicrobianas. Favorece la digestión, fortalece el sistema inmunológico, protege contra infecciones y contribuye a la salud cardiovascular, gracias a sus compuestos como carvacrol y timol.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#modificado \n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "from itertools import cycle\n",
    "\n",
    "def spinner_task(stop_event):\n",
    "    spinner = cycle(['|', '/', '-', '\\\\'])\n",
    "    while not stop_event.is_set():\n",
    "        sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.1)\n",
    "    sys.stdout.write('\\r' + ' ' * 20 + '\\r')  # limpia la línea del spinner\n",
    "\n",
    "def ejercicio1_spinner_simple():\n",
    "    prompt = \"resumen en 30 palabras :Explica los beneficios del oregano para la salud\"\n",
    "    print(\"=== EJERCICIO 1A: SPINNER SIMPLE ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    response_text = \"\"\n",
    "    stop_event = threading.Event()\n",
    "    spinner_thread = threading.Thread(target=spinner_task, args=(stop_event,))\n",
    "    spinner_thread.start()\n",
    "\n",
    "    try:\n",
    "        # Recibe e imprime chunks normalmente (sin spinner aquí)\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "        stop_event.set()\n",
    "        spinner_thread.join()\n",
    "        print(\"\\n✓ Completado!\")\n",
    "        print(f\"\\nRespuesta completa:\\n{response_text}\\n\")\n",
    "    except Exception as e:\n",
    "        stop_event.set()\n",
    "        spinner_thread.join()\n",
    "        print(f\"\\nError: {e}\")\n",
    "\n",
    "ejercicio1_spinner_simple()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2190b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJERCICIO 1B: BARRA DE PROGRESO ===\n",
      "[██████████████████████████████] 100% (117 chars)\n",
      "\n",
      "\n",
      "Respuesta final:\n",
      "La fotosíntesis es el proceso donde las plantas convierten luz solar, agua y dióxido de carbono en glucosa y oxígeno.\n",
      "\n",
      "✅ Barra de progreso completada!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def ejercicio1_barra_progreso():\n",
    "    \"\"\"Barra de progreso visual basada en longitud de texto generado\"\"\"\n",
    "    \n",
    "    prompt = \"resume en 20 palabras:Describe el proceso de fotosíntesis en las plantas\"\n",
    "    print(\"=== EJERCICIO 1B: BARRA DE PROGRESO ===\")\n",
    "    \n",
    "    response_text = \"\"\n",
    "    last_percent = 0\n",
    "    bar_length = 30\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Progreso estimado basado en cantidad de caracteres\n",
    "            total_estimate = 30  # puedes ajustar según lo largo que esperas que sea la respuesta\n",
    "            progress = min(len(response_text) / total_estimate, 1.0)\n",
    "            \n",
    "            filled_length = int(bar_length * progress)\n",
    "            bar = '█' * filled_length + '░' * (bar_length - filled_length)\n",
    "            percent = int(progress * 100)\n",
    "            \n",
    "            # Solo actualizar si hay un cambio real en porcentaje\n",
    "            if percent != last_percent:\n",
    "                sys.stdout.write(f'\\r[{bar}] {percent}% ({len(response_text)} chars)')\n",
    "                sys.stdout.flush()\n",
    "                last_percent = percent\n",
    "            \n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        # Completa la barra al final\n",
    "        sys.stdout.write('\\r[' + '█'*bar_length + '] 100% (' + str(len(response_text)) + ' chars)\\n')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        print(f\"\\n\\nRespuesta final:\\n{response_text}\\n\")\n",
    "        print(\"✅ Barra de progreso completada!\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "\n",
    "ejercicio1_barra_progreso()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6214408",
   "metadata": {},
   "source": [
    "## Comparación: Streaming vs No-Streaming\n",
    "\n",
    "Veamos la diferencia en experiencia de usuario entre ambos enfoques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8e5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACIÓN: STREAMING vs NO-STREAMING ===\\n\n",
      "1. SIN STREAMING:\n",
      "--------------------\n",
      "Esperando respuesta completa...\n",
      "\\n[Respuesta recibida después de 2.90 segundos]\n",
      "El orégano es una hierba aromática que ofrece múltiples beneficios para la salud. Su alto contenido de antioxidantes ayuda a combatir el estrés oxidativo, protegiendo las células del daño. Además, posee propiedades antimicrobianas que pueden contribuir a la lucha contra infecciones bacterianas y fúngicas. El orégano es rico en compuestos antiinflamatorios, lo que puede aliviar síntomas de enfermedades inflamatorias y mejorar la salud digestiva al estimular la producción de jugos gástricos. También se le atribuyen efectos beneficiosos en la salud respiratoria, al actuar como expectorante natural. Su uso en la cocina no solo realza el sabor de los platillos, sino que también promueve una alimentación más saludable. En resumen, el orégano es una valiosa adición tanto en la gastronomía como en la medicina natural, ofreciendo propiedades que favorecen el bienestar general.\n",
      "\\n============================================================\\n\n",
      "2. CON STREAMING:\n",
      "------------------\n",
      "Respuesta en tiempo real:\n",
      "El orégano es una hierba aromática que ofrece múltiples beneficios para la salud. Su riqueza en antioxidantes ayuda a combatir el daño celular y a fortalecer el sistema inmunológico. Además, contiene compuestos antimicrobianos que pueden combatir bacterias y hongos, promoviendo una mejor salud digestiva. El orégano también es conocido por sus propiedades antiinflamatorias, lo que puede aliviar dolores y reducir la inflamación en el cuerpo. Su consumo se asocia con la mejora de la salud respiratoria, aliviando síntomas de resfriados y alergias. Asimismo, su perfil nutricional incluye vitaminas y minerales esenciales, como vitamina K y manganeso, que son importantes para el metabolismo y la salud ósea. Incorporar orégano en la dieta no solo enriquece los platos con su sabor distintivo, sino que también proporciona una serie de beneficios que contribuyen al bienestar general.\\n\\n[Streaming completado en 6.47 segundos]\n",
      "\\n============================================================\n",
      "OBSERVACIONES:\n",
      "- Sin streaming: El usuario espera sin feedback\n",
      "- Con streaming: El usuario ve progreso inmediato\n",
      "- Mejor percepción de velocidad con streaming\n",
      "- Streaming es especial para respuestas largas\n"
     ]
    }
   ],
   "source": [
    "# Comparación entre streaming y no-streaming\n",
    "def comparar_streaming():\n",
    "\n",
    "    # Modelo sin streaming\n",
    "    llm_no_stream = ChatOpenAI(\n",
    "        base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "        model = \"openai/gpt-4o-mini\",               \n",
    "        temperature=0.7,\n",
    "        streaming=False  # Sin streaming\n",
    "       \n",
    "    )\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=\"https://models.github.ai/inference\",  #descubri que aqui  cambia de url base  \n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),               \n",
    "        model = \"openai/gpt-4o-mini\",               \n",
    "        temperature=0.7,\n",
    "        streaming=False  # Sin streaming\n",
    "       \n",
    "    )\n",
    "    \n",
    "    prompt = \"resumido en 150 palabras :Escribe un párrafo sobre beneficions del oregano\"\n",
    "    \n",
    "    print(\"=== COMPARACIÓN: STREAMING vs NO-STREAMING ===\\\\n\")\n",
    "    \n",
    "    # 1. Sin streaming\n",
    "    print(\"1. SIN STREAMING:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Esperando respuesta completa...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = llm_no_stream.invoke([HumanMessage(content=prompt)])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\\\n[Respuesta recibida después de {end_time - start_time:.2f} segundos]\")\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60 + \"\\\\n\")\n",
    "    \n",
    "    # 2. Con streaming\n",
    "    print(\"2. CON STREAMING:\")\n",
    "    print(\"-\" * 18)\n",
    "    print(\"Respuesta en tiempo real:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.03)  # Simular pausa para efecto visual\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\\\n\\\\n[Streaming completado en {end_time - start_time:.2f} segundos]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"OBSERVACIONES:\")\n",
    "    print(\"- Sin streaming: El usuario espera sin feedback\")\n",
    "    print(\"- Con streaming: El usuario ve progreso inmediato\")\n",
    "    print(\"- Mejor percepción de velocidad con streaming\")\n",
    "    print(\"- Streaming es especial para respuestas largas\")\n",
    "\n",
    "# Ejecutar comparación\n",
    "comparar_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ad79d",
   "metadata": {},
   "source": [
    "## Implementación de un Chatbot Simple con Streaming\n",
    "\n",
    "Creemos un chatbot básico que demuestre el streaming en un contexto práctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a03cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHATBOT CON STREAMING ===\n",
      "Escribe 'salir' para terminar la conversación\\n\n"
     ]
    }
   ],
   "source": [
    "# Chatbot simple con streaming\n",
    "def chatbot_streaming():\n",
    "    print(\"=== CHATBOT CON STREAMING ===\")\n",
    "    print(\"Escribe 'salir' para terminar la conversación\\\\n\")\n",
    "    \n",
    "    # Configurar asistente con personalidad\n",
    "    system_message = \"\"\"Eres un asistente útil y amigable especializado en tecnología. \n",
    "    Respondes de manera clara y concisa, y siempre intentas ser educativo.\"\"\"\n",
    "    \n",
    "    while True:\n",
    "        # Obtener input del usuario\n",
    "        user_input = input(\"\\\\n🧑 Tú: \")\n",
    "        \n",
    "        if user_input.lower() in ['salir', 'exit', 'quit']:\n",
    "            print(\"\\\\n👋 ¡Hasta luego!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input.strip():\n",
    "            continue\n",
    "            \n",
    "        print(\"\\\\n🤖 Asistente: \", end=\"\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Streaming de la respuesta\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "            \n",
    "            # Convertir a formato LangChain\n",
    "            from langchain.schema import SystemMessage\n",
    "            lc_messages = [\n",
    "                SystemMessage(content=system_message),\n",
    "                HumanMessage(content=user_input)\n",
    "            ]\n",
    "            \n",
    "            full_response = \"\"\n",
    "            for chunk in llm.stream(lc_messages):\n",
    "                content = chunk.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "                time.sleep(0.02)\n",
    "                \n",
    "            print()  # Nueva línea al final\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\\\n\\\\n⏸️ Interrumpido por el usuario\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n❌ Error: {e}\")\n",
    "            \n",
    "    print(\"\\\\n¡Gracias por usar el chatbot!\")\n",
    "\n",
    "# Ejecutar chatbot (¡Pruébalo!)\n",
    "chatbot_streaming() \n",
    " # Descomenta esta línea para ejecutar\n",
    "\n",
    "print(\"💡 Descomenta la línea anterior para probar el chatbot interactivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060e43c",
   "metadata": {},
   "source": [
    "## Streaming Avanzado con Manejo de Chunks\n",
    "\n",
    "Podemos procesar cada chunk individualmente para crear experiencias más sofisticadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86fa1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING AVANZADO CON ANÁLISIS ===\n",
      "Analizando chunks conforme llegan...\n",
      "\n",
      "La inteligencia artificial (IA) es\\n[Progreso: 10 chunks, ~8 palabras]\\n\n",
      " una rama de la informática que busca crear sistemas capaces\\n[Progreso: 20 chunks, ~18 palabras]\\n\n",
      " de realizar tareas que requieren inteligencia humana. El machine\\n[Progreso: 30 chunks, ~28 palabras]\\n\n",
      " learning, una subdisciplina de la IA,\\n[Progreso: 40 chunks, ~38 palabras]\\n\n",
      " funciona mediante algoritmos que permiten a las máquinas aprender\\n[Progreso: 50 chunks, ~48 palabras]\\n\n",
      " de datos y mejorar su rendimiento en tareas específicas sin\\n[Progreso: 60 chunks, ~58 palabras]\\n\n",
      " ser programadas explícitamente.\\n\\n=== ESTADÍSTICAS FINALES ===\n",
      "Total de chunks: 66\n",
      "Palabras aproximadas: 63\n",
      "Caracteres totales: 355\n",
      "Promedio chars/chunk: 5.4\n"
     ]
    }
   ],
   "source": [
    "# Streaming con análisis de chunks\n",
    "def streaming_avanzado():\n",
    "    prompt = \" en 50 palabras Explica qué es la inteligencia artificial y cómo funciona el machine learning\"\n",
    "    \n",
    "    print(\"=== STREAMING AVANZADO CON ANÁLISIS ===\")\n",
    "    print(\"Analizando chunks conforme llegan...\\n\")\n",
    "    \n",
    "    # Variables para estadísticas\n",
    "    chunk_count = 0\n",
    "    total_content = \"\"\n",
    "    words_processed = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            chunk_count += 1\n",
    "            content = chunk.content\n",
    "            total_content += content\n",
    "            \n",
    "            # Contar palabras aproximadas\n",
    "            if content.strip():\n",
    "                words_in_chunk = len(content.split())\n",
    "                words_processed += words_in_chunk\n",
    "            \n",
    "            # Mostrar progreso cada 10 chunks\n",
    "            if chunk_count % 10 == 0:\n",
    "                print(f\"\\\\n[Progreso: {chunk_count} chunks, ~{words_processed} palabras]\\\\n\")\n",
    "            \n",
    "            # Imprimir el contenido\n",
    "            print(content, end=\"\", flush=True)\n",
    "            time.sleep(0.02)  # Pausa ligeramente más larga para ver el análisis\n",
    "        \n",
    "        # Estadísticas finales\n",
    "        print(f\"\\\\n\\\\n=== ESTADÍSTICAS FINALES ===\")\n",
    "        print(f\"Total de chunks: {chunk_count}\")\n",
    "        print(f\"Palabras aproximadas: {words_processed}\")\n",
    "        print(f\"Caracteres totales: {len(total_content)}\")\n",
    "        print(f\"Promedio chars/chunk: {len(total_content)/chunk_count if chunk_count > 0 else 0:.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\n✗ Error: {e}\")\n",
    "\n",
    "# Ejecutar streaming avanzado\n",
    "streaming_avanzado()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac251a9d",
   "metadata": {},
   "source": [
    "## Consideraciones Técnicas del Streaming\n",
    "\n",
    "### Cuándo Usar Streaming:\n",
    "✅ **SÍ usar streaming:**\n",
    "- Respuestas largas (>100 tokens)\n",
    "- Aplicaciones interactivas\n",
    "- Chatbots y asistentes\n",
    "- Demostraciones en vivo\n",
    "- Cuando la UX es prioritaria\n",
    "\n",
    "❌ **NO usar streaming:**\n",
    "- Respuestas muy cortas\n",
    "- Procesamiento batch\n",
    "- APIs de backend sin interfaz\n",
    "- Cuando necesitas la respuesta completa antes de procesar\n",
    "\n",
    "### Mejores Prácticas:\n",
    "1. **Manejo de errores**: Siempre incluye try/catch\n",
    "2. **Indicadores visuales**: Muestra progreso al usuario\n",
    "3. **Cancelación**: Permite al usuario interrumpir\n",
    "4. **Buffer management**: Para interfaces web, considera buffering\n",
    "5. **Performance**: Monitorea el uso de recursos\n",
    "\n",
    "## Ejercicios Prácticos\n",
    "\n",
    "### Ejercicio 1: Indicador de Progreso\n",
    "Modifica el código para mostrar un indicador de progreso (spinner, barra, porcentaje).\n",
    "\n",
    "### Ejercicio 2: Streaming con Filtros\n",
    "Implementa streaming que filtre o procese chunks específicos (ej: resaltar palabras clave).\n",
    "\n",
    "### Ejercicio 3: Chatbot Mejorado\n",
    "Extiende el chatbot con:\n",
    "- Historial de conversación\n",
    "- Comandos especiales (/help, /clear)\n",
    "- Diferentes personalidades\n",
    "\n",
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Streaming** mejora la percepción de velocidad\n",
    "2. **Chunks** se procesan individualmente en tiempo real\n",
    "3. **UX** es significativamente mejor con streaming\n",
    "4. **Implementación** requiere manejo cuidadoso de generadores\n",
    "5. **Casos de uso** específicos donde streaming aporta valor\n",
    "\n",
    "## Próximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos la **memoria en LangChain**, que nos permite mantener contexto entre múltiples interacciones del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced2c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando respuesta...\n",
      "✅ Completado!        \n",
      "\n",
      "**Python** es un **lenguaje de programación** de alto nivel, interpretado, multiparadigma (soporta programación orientada a objetos, imperativa y funcional), y de propósito general. Fue creado por **Guido van Rossum** y publicado en 1991. Su diseño enfatiza la legibilidad del código y una sintaxis sencilla que permite a los programadores expresar conceptos en menos líneas de código que otros lenguajes.\n",
      "\n",
      "### Ventajas de Python\n",
      "\n",
      "1. **Sintaxis sencilla y legible**  \n",
      "   Python está diseñado para ser fácil de leer y escribir, lo que facilita el aprendizaje y el desarrollo rápido.\n",
      "\n",
      "2. **Gran comunidad y soporte**  \n",
      "   Cuenta con una comunidad activa que aporta miles de librerías\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#import time\n",
    "from itertools import cycle\n",
    "#from langchain_openai import ChatOpenAI\n",
    "#from langchain.schema import HumanMessage\n",
    "\n",
    "def spinner_progreso():\n",
    "    \"\"\"Spinner que rota mientras llegan los chunks\"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Caracteres del spinner\n",
    "    spinner = cycle(['⠋', '⠙', '⠹', '⠸', '⠼', '⠴', '⠦', '⠧', '⠇', '⠏'])\n",
    "    \n",
    "    prompt = \"Explica qué es Python y sus ventajas\"\n",
    "    response_text = \"\"\n",
    "    \n",
    "    print(\"Generando respuesta...\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Mostrar spinner\n",
    "            sys.stdout.write(f'\\r{next(spinner)} Procesando...')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            response_text += chunk.content\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        # Limpiar spinner y mostrar resultado\n",
    "        sys.stdout.write('\\r✅ Completado!        \\n\\n')\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "spinner_progreso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b67c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Barra de Progreso ===\n",
      "[█████████████████████████] 100% (617 chars)\n",
      "\n",
      "Respuesta completa:\n",
      "Claro, aquí tienes una descripción paso a paso del proceso de **machine learning** (aprendizaje automático):\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Definición del problema**\n",
      "   - Identifica y comprende el problema que deseas resolver.\n",
      "   - Ejemplo: ¿Quieres clasificar correos como spam/no spam?\n",
      "\n",
      "### 2. **Recolección de datos**\n",
      "   - Obtén datos relevantes para el problema.\n",
      "   - Pueden provenir de bases de datos, sensores, web, etc.\n",
      "\n",
      "### 3. **Preprocesamiento de datos**\n",
      "   - Limpieza: Elimina duplicados, corrige errores y trata valores faltantes.\n",
      "   - Transformación: Normaliza o estandariza datos, convierte variables categóricas en num\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "def barra_progreso():\n",
    "    \"\"\"Barra de progreso basada en caracteres generados\"\"\"\n",
    "    \n",
    "    prompt = \"Describe el proceso de machine learning paso a paso\"\n",
    "    response_text = \"\"\n",
    "    bar_length = 25\n",
    "    estimated_total = 400  # Estimación de caracteres esperados\n",
    "    \n",
    "    print(\"=== Barra de Progreso ===\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Calcular progreso\n",
    "            progress = min(len(response_text) / estimated_total, 1.0)\n",
    "            filled = int(bar_length * progress)\n",
    "            \n",
    "            # Crear barra visual\n",
    "            bar = '█' * filled + '░' * (bar_length - filled)\n",
    "            percent = int(progress * 100)\n",
    "            \n",
    "            # Actualizar barra\n",
    "            sys.stdout.write(f'\\r[{bar}] {percent}% ({len(response_text)} chars)')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            time.sleep(0.03)\n",
    "        \n",
    "        # Completar al 100%\n",
    "        sys.stdout.write(f'\\r[{\"█\" * bar_length}] 100% ({len(response_text)} chars)\\n\\n')\n",
    "        print(\"Respuesta completa:\")\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "barra_progreso()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6143ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Contador de Palabras ===\n",
      "Generando respuesta...\n",
      "\n",
      "📝 Palabras: 103 | Caracteres: 727\n",
      "\n",
      "✅ Generación completada!\n",
      "📊 Estadísticas finales: 103 palabras, 727 caracteres\n",
      "\n",
      "Respuesta:\n",
      "La inteligencia artificial (IA) ofrece numerosos beneficios en diferentes ámbitos de la vida y sectores productivos. Algunos de los principales son:\n",
      "\n",
      "1. **Automatización de tareas**: Permite que procesos repetitivos o complejos se realicen de forma automática, ahorrando tiempo y reduciendo errores humanos.\n",
      "\n",
      "2. **Mejora en la toma de decisiones**: La IA puede analizar grandes cantidades de datos y ofrecer recomendaciones o predicciones más precisas que las realizadas manualmente.\n",
      "\n",
      "3. **Personalización**: En áreas como el comercio electrónico, la educación y la salud, la IA puede adaptar productos, servicios o contenidos a las necesidades y preferencias individuales de los usuarios.\n",
      "\n",
      "4. **Eficiencia operativa**: Ayuda a\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def contador_palabras():\n",
    "    \"\"\"Muestra el conteo de palabras conforme se genera el texto\"\"\"\n",
    "    \n",
    "    prompt = \"Cuéntame sobre los beneficios de la inteligencia artificial\"\n",
    "    response_text = \"\"\n",
    "    \n",
    "    print(\"=== Contador de Palabras ===\")\n",
    "    print(\"Generando respuesta...\\n\")\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            response_text += chunk.content\n",
    "            \n",
    "            # Contar palabras\n",
    "            words = len(re.findall(r'\\b\\w+\\b', response_text))\n",
    "            chars = len(response_text)\n",
    "            \n",
    "            # Mostrar progreso\n",
    "            sys.stdout.write(f'\\r📝 Palabras: {words} | Caracteres: {chars}')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(f\"\\n\\n✅ Generación completada!\")\n",
    "        print(f\"📊 Estadísticas finales: {words} palabras, {chars} caracteres\\n\")\n",
    "        print(\"Respuesta:\")\n",
    "        print(response_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "contador_palabras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4604485a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING CON RESALTADO DE PALABRAS CLAVE ===\n",
      "🔍 Palabras clave: python, machine learning, inteligencia artificial, algoritmo, datos, modelo\n",
      "\n",
      "Respuesta (palabras clave resaltadas con *):\n",
      "--------------------------------------------------\n",
      "***PYTHON*** es un lenguaje de programación de alto nivel, de propósito general, que se caracteriza por ser sencillo, legible y fácil de aprender. Fue creado a finales de los años 80 y desde entonces ha ganado enorme popularidad, especialmente en áreas como ciencia de *DATOS*, desarrollo web, automatización y, de manera destacada, en **machine learning (aprendizaje automático)** e **inteligencia artificial (IA)**.\n",
      "\n",
      "### ¿Qué es *PYTHON*?\n",
      "\n",
      "- **Sintaxis clara y sencilla**, lo que facilita el desarrollo y mantenimiento de código.\n",
      "- Es **multiparadigma**, permitiendo programación orientada a objetos, imperativa y funcional.\n",
      "- Posee una **gran comunidad** y una **amplia colección de bibliotecas\n",
      "--------------------------------------------------\n",
      "✅ Streaming completado!\n",
      "🎯 Palabras clave resaltadas: 3\n"
     ]
    }
   ],
   "source": [
    "def streaming_con_resaltado():\n",
    "    \"\"\"Resalta palabras clave específicas durante el streaming\"\"\"\n",
    "    \n",
    "    # Palabras clave a resaltar\n",
    "    keywords = [\"python\", \"machine learning\", \"inteligencia artificial\", \"algoritmo\", \"datos\", \"modelo\"]\n",
    "    \n",
    "    prompt = \"Explica qué es Python y cómo se usa en machine learning e inteligencia artificial\"\n",
    "    \n",
    "    print(\"=== STREAMING CON RESALTADO DE PALABRAS CLAVE ===\")\n",
    "    print(f\"🔍 Palabras clave: {', '.join(keywords)}\\n\")\n",
    "    print(\"Respuesta (palabras clave resaltadas con *):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response_text = \"\"\n",
    "    highlighted_count = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            content = chunk.content\n",
    "            response_text += content\n",
    "            \n",
    "            # Procesar cada chunk para resaltar palabras clave\n",
    "            processed_content = content\n",
    "            for keyword in keywords:\n",
    "                # Buscar la palabra clave (insensible a mayúsculas/minúsculas)\n",
    "                pattern = re.compile(re.escape(keyword), re.IGNORECASE)\n",
    "                if pattern.search(processed_content):\n",
    "                    processed_content = pattern.sub(f\"*{keyword.upper()}*\", processed_content)\n",
    "                    highlighted_count += 1\n",
    "            \n",
    "            # Mostrar el chunk procesado\n",
    "            print(processed_content, end=\"\", flush=True)\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(f\"\\n{'-' * 50}\")\n",
    "        print(f\"✅ Streaming completado!\")\n",
    "        print(f\"🎯 Palabras clave resaltadas: {highlighted_count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "\n",
    "# Ejecutar\n",
    "streaming_con_resaltado()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
