{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluaci√≥n de Sistemas RAG con LangSmith\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender la importancia de la evaluaci√≥n en sistemas RAG.\n",
    "- Configurar LangSmith para trazabilidad y evaluaci√≥n.\n",
    "- Crear un dataset de evaluaci√≥n con preguntas y respuestas de referencia.\n",
    "- Ejecutar evaluadores autom√°ticos para m√©tricas como relevancia y fidelidad.\n",
    "- Analizar los resultados de la evaluaci√≥n para optimizar el sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es LangSmith?\n",
    "\n",
    "LangSmith es una plataforma de LangChain para la observabilidad, el monitoreo y la evaluaci√≥n de aplicaciones construidas con Modelos de Lenguaje Grandes (LLMs). Permite visualizar cada paso de una cadena o agente, analizar su rendimiento y evaluar la calidad de las respuestas de forma sistem√°tica.\n",
    "\n",
    "Para un sistema RAG, LangSmith nos ayuda a responder preguntas clave:\n",
    "- **Recuperaci√≥n (Retrieval)**: ¬øLos documentos que encontramos son relevantes para la pregunta?\n",
    "- **Generaci√≥n (Generation)**: ¬øLa respuesta generada es fiel a los documentos recuperados? ¬øResponde correctamente a la pregunta del usuario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai langsmith langchain httpx -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langsmith import Client\n",
    "import json\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuraci√≥n de Variables de Entorno\n",
    "\n",
    "Para que LangSmith capture las trazas de nuestra aplicaci√≥n, necesitamos configurar cuatro variables de entorno:\n",
    "1. `LANGCHAIN_TRACING_V2`: Se establece en `\"true\"` para activar la trazabilidad.\n",
    "2. `LANGCHAIN_API_KEY`: Tu clave de API de LangSmith. La puedes obtener en [smith.langchain.com](https://smith.langchain.com).\n",
    "3. `LANGCHAIN_PROJECT`: El nombre del proyecto bajo el cual se agrupar√°n las trazas. Esto es muy √∫til para organizar el trabajo.\n",
    "4. `OPENAI_API_KEY`: Tu clave de API de OpenAI para que el modelo de lenguaje funcione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Variables de entorno y cliente de LangSmith configurados\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el cliente de LangSmith\n",
    "client = Client()\n",
    "\n",
    "print(\"‚úÖ Variables de entorno y cliente de LangSmith configurados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sistema RAG B√°sico\n",
    "\n",
    "Reutilizaremos el sistema RAG simple del notebook anterior. Este sistema utiliza una lista de documentos en memoria, una funci√≥n de recuperaci√≥n por palabras clave y un LLM para generar respuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Base de datos con 5 documentos cargada.\n",
      "‚úÖ Cliente OpenAI inicializado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Base de documentos\n",
    "documents = [\n",
    "    \"La inteligencia artificial es una rama de la inform√°tica que busca crear m√°quinas capaces de realizar tareas que requieren inteligencia humana.\",\n",
    "    \"Los modelos de lenguaje grande (LLM) son sistemas de IA entrenados en enormes cantidades de texto para generar y comprender lenguaje natural.\",\n",
    "    \"RAG (Retrieval-Augmented Generation) combina la b√∫squeda de informaci√≥n relevante con la generaci√≥n de texto para producir respuestas m√°s precisas.\",\n",
    "    \"LangChain es un framework que facilita el desarrollo de aplicaciones con modelos de lenguaje, proporcionando herramientas para cadenas y agentes.\",\n",
    "    \"El prompt engineering es la pr√°ctica de dise√±ar instrucciones efectivas para obtener los mejores resultados de los modelos de IA.\"\n",
    "]\n",
    "\n",
    "# Cliente de OpenAI (siguiendo el patr√≥n del proyecto)\n",
    "def initialize_client():\n",
    "    client = OpenAI(\n",
    "        base_url=os.getenv(\"GITHUB_BASE_URL\", \"https://models.inference.ai.azure.com\"),\n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\")\n",
    "    )\n",
    "    return client\n",
    "\n",
    "openai_client = initialize_client()\n",
    "\n",
    "print(f\"üìö Base de datos con {len(documents)} documentos cargada.\")\n",
    "print(\"‚úÖ Cliente OpenAI inicializado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones del pipeline RAG definidas y trazables\n"
     ]
    }
   ],
   "source": [
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "# Envolvemos las funciones con el decorador @traceable para que LangSmith las capture\n",
    "\n",
    "@traceable(name=\"Recuperacion de Documentos\")\n",
    "def simple_retrieval(query, documents):\n",
    "    relevant_docs = []\n",
    "    query_lower = query.lower()\n",
    "    for doc in documents:\n",
    "        if any(word in doc.lower() for word in query_lower.split()):\n",
    "            relevant_docs.append(doc)\n",
    "    return relevant_docs[:3]\n",
    "\n",
    "@traceable(name=\"Generacion de Respuesta\")\n",
    "def generate_response(client, query, context):\n",
    "    prompt = f\"\"\"Contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta: {query}\n",
    "\n",
    "Responde bas√°ndote √∫nicamente en el contexto proporcionado.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "@traceable(name=\"Pipeline RAG Completo\")\n",
    "def rag_pipeline(query):\n",
    "    context_docs = simple_retrieval(query, documents)\n",
    "    context = \"\".join(context_docs)\n",
    "    answer = generate_response(openai_client, query, context)\n",
    "    return {\"answer\": answer, \"context\": context_docs}\n",
    "\n",
    "print(\"‚úÖ Funciones del pipeline RAG definidas y trazables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de Trazabilidad\n",
    "\n",
    "Ahora, si ejecutamos nuestro pipeline, LangSmith registrar√° la ejecuci√≥n completa, incluyendo los pasos intermedios que decoramos. Puedes ir a tu proyecto en LangSmith para ver la traza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SyncHttpxClientWrapper.__del__ at 0x113aff4c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 801, in __del__\n",
      "    if self.is_closed:\n",
      "       ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/httpx/_client.py\", line 228, in is_closed\n",
      "    return self._state == ClientState.CLOSED\n",
      "           ^^^^^^^^^^^\n",
      "AttributeError: 'SyncHttpxClientWrapper' object has no attribute '_state'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG (Retrieval-Augmented Generation) es un enfoque que combina la b√∫squeda de informaci√≥n relevante con la generaci√≥n de texto para producir respuestas m√°s precisas.\n"
     ]
    }
   ],
   "source": [
    "resultado = rag_pipeline(\"¬øQu√© es RAG?\")\n",
    "print(resultado[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creaci√≥n de un Dataset de Evaluaci√≥n\n",
    "\n",
    "Para evaluar nuestro sistema, necesitamos un \"ground truth\" (verdad fundamental), es decir, un conjunto de preguntas y las respuestas que consideramos correctas. En LangSmith, esto se gestiona a trav√©s de Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Dataset 'Dataset RAG B√°sico - Fundamentos IA' existente eliminado.\n",
      "‚úÖ Dataset 'Dataset RAG B√°sico - Fundamentos IA' creado.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Dataset RAG B√°sico - Fundamentos IA\"\n",
    "description = \"Preguntas y respuestas sobre conceptos b√°sicos de IA para evaluar un RAG simple.\"\n",
    "\n",
    "# Eliminar dataset si ya existe para evitar duplicados\n",
    "try:\n",
    "    existing_dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "    client.delete_dataset(dataset_id=str(existing_dataset.id))\n",
    "    print(f\"üóëÔ∏è Dataset '{dataset_name}' existente eliminado.\")\n",
    "except Exception:\n",
    "    pass # El dataset no exist√≠a, no hay nada que hacer\n",
    "\n",
    "# Crear el nuevo dataset\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=description,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset '{dataset_name}' creado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A√±adir Ejemplos al Dataset\n",
    "\n",
    "Cada ejemplo consta de:\n",
    "- `inputs`: Un diccionario con las entradas de nuestro sistema (en este caso, la `query`).\n",
    "- `outputs`: Un diccionario con la salida de referencia que esperamos (la `answer` correcta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 3 ejemplos a√±adidos al dataset 'Dataset RAG B√°sico - Fundamentos IA'.\n"
     ]
    }
   ],
   "source": [
    "client.create_example(\n",
    "    inputs={\"query\": \"¬øQu√© es la inteligencia artificial?\"},\n",
    "    outputs={\"answer\": \"La inteligencia artificial es una rama de la inform√°tica que busca crear m√°quinas capaces de realizar tareas que requieren inteligencia humana.\"},\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "client.create_example(\n",
    "    inputs={\"query\": \"¬øPara qu√© sirve LangChain?\"},\n",
    "    outputs={\"answer\": \"LangChain es un framework que facilita el desarrollo de aplicaciones con modelos de lenguaje, proporcionando herramientas para cadenas y agentes.\"},\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "client.create_example(\n",
    "    inputs={\"query\": \"Explica qu√© es RAG\"},\n",
    "    outputs={\"answer\": \"RAG (Retrieval-Augmented Generation) combina la b√∫squeda de informaci√≥n relevante con la generaci√≥n de texto para producir respuestas m√°s precisas.\"},\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ 3 ejemplos a√±adidos al dataset '{dataset_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ejecuci√≥n de la Evaluaci√≥n\n",
    "\n",
    "Ahora que tenemos el sistema y el dataset, podemos ejecutar la evaluaci√≥n. LangSmith utilizar√° un LLM para comparar las respuestas generadas por nuestro `rag_pipeline` con las respuestas de referencia (`ground truth`) de nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'RAG B√°sico - Primera Prueba-844ffd37' at:\n",
      "https://smith.langchain.com/o/3a147d9f-375a-49e5-b37f-01cf8bf3ea9d/datasets/0c2e95e5-a5a5-4133-812c-1f5f54a9a810/compare?selectedSessions=8c0b5725-7396-4e11-99f6-9b355281e432\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Exception ignored in: Exception ignored in: <function SyncHttpxClientWrapper.__del__ at 0x113aff4c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 801, in __del__\n",
      "<function SyncHttpxClientWrapper.__del__ at 0x113aff4c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 801, in __del__\n",
      "Exception ignored in: <function SyncHttpxClientWrapper.__del__ at 0x113aff4c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 801, in __del__\n",
      "    if self.is_closed:\n",
      "       ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/httpx/_client.py\", line 228, in is_closed\n",
      "    if self.is_closed:\n",
      "       ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/httpx/_client.py\", line 228, in is_closed\n",
      "    if self.is_closed:\n",
      "       ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/httpx/_client.py\", line 228, in is_closed\n",
      "    return self._state == ClientState.CLOSED\n",
      "           ^^^^^^^^^^^\n",
      "AttributeError: 'SyncHttpxClientWrapper' object has no attribute '_state'\n",
      "    return self._state == ClientState.CLOSED\n",
      "           ^^^^^^^^^^^\n",
      "AttributeError: 'SyncHttpxClientWrapper' object has no attribute '_state'\n",
      "    return self._state == ClientState.CLOSED\n",
      "           ^^^^^^^^^^^\n",
      "AttributeError: 'SyncHttpxClientWrapper' object has no attribute '_state'\n",
      "/usr/local/lib/python3.11/site-packages/langsmith/run_helpers.py:609: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "Error running evaluator <DynamicRunEvaluator DynamicRunEvaluator> on run f0b0d103-ac26-44b5-ad5d-ca5800ebb48a: ValueError(\"Missing some input keys: {'answer', 'query'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/evaluation/_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/evaluation/evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py\", line 191, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 386, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 167, in invoke\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 155, in invoke\n",
      "    self._validate_inputs(inputs)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 287, in _validate_inputs\n",
      "    raise ValueError(f\"Missing some input keys: {missing_keys}\")\n",
      "ValueError: Missing some input keys: {'answer', 'query'}\n",
      "1it [00:03,  3.13s/it]Error running evaluator <DynamicRunEvaluator DynamicRunEvaluator> on run 061e17c1-9e09-4b0e-ae0e-01710cbdae53: ValueError(\"Missing some input keys: {'answer', 'query'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/evaluation/_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/evaluation/evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py\", line 191, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 386, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 167, in invoke\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 155, in invoke\n",
      "    self._validate_inputs(inputs)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 287, in _validate_inputs\n",
      "    raise ValueError(f\"Missing some input keys: {missing_keys}\")\n",
      "ValueError: Missing some input keys: {'answer', 'query'}\n",
      "2it [00:06,  3.09s/it]Error running evaluator <DynamicRunEvaluator DynamicRunEvaluator> on run 9d9f0281-63a6-40f9-955d-243f7c5345a7: ValueError(\"Missing some input keys: {'answer', 'query'}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/evaluation/_runner.py\", line 1357, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/evaluation/evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 612, in wrapper\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 609, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py\", line 191, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 386, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 167, in invoke\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 155, in invoke\n",
      "    self._validate_inputs(inputs)\n",
      "  File \"/usr/local/lib/python3.11/site-packages/langchain/chains/base.py\", line 287, in _validate_inputs\n",
      "    raise ValueError(f\"Missing some input keys: {missing_keys}\")\n",
      "ValueError: Missing some input keys: {'answer', 'query'}\n",
      "3it [00:06,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluaci√≥n completada. Revisa los resultados en LangSmith.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "# Cargamos un evaluador predefinido de LangChain. \"qa\" es un evaluador de exactitud.\n",
    "evaluator = load_evaluator(\"qa\")\n",
    "\n",
    "# La funci√≥n que ser√° evaluada. Debe aceptar 'inputs' como un diccionario.\n",
    "def target_function(inputs):\n",
    "    return rag_pipeline(inputs[\"query\"])\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    target_function,  # La funci√≥n a evaluar\n",
    "    data=dataset_name,  # El nombre de nuestro dataset en LangSmith\n",
    "    evaluators=[evaluator], # Pasamos la lista de objetos evaluadores\n",
    "    experiment_prefix=\"RAG B√°sico - Primera Prueba\", # Prefijo para el nombre del experimento\n",
    "    metadata={\"version\": \"1.0.0\"}, # Metadatos para seguimiento\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Evaluaci√≥n completada. Revisa los resultados en LangSmith.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de Resultados\n",
    "\n",
    "Una vez completada la evaluaci√≥n, puedes navegar a la pesta√±a **Experiments** en tu proyecto de LangSmith.\n",
    "\n",
    "All√≠ encontrar√°s:\n",
    "1. Un resumen del experimento con las puntuaciones medias de cada m√©trica.\n",
    "2. Una tabla detallada con cada pregunta del dataset, la respuesta generada, la respuesta de referencia y las puntuaciones de la evaluaci√≥n.\n",
    "3. Para cada fila, puedes hacer clic para ver la traza completa y entender por qu√© el sistema respondi√≥ de esa manera (qu√© documentos recuper√≥, qu√© prompt se us√≥, etc.).\n",
    "\n",
    "Este an√°lisis te permite identificar puntos d√©biles. Por ejemplo:\n",
    "- **Puntuaciones bajas de `correctness`**: Puede que la recuperaci√≥n no est√© funcionando bien o que el prompt de generaci√≥n necesite ajustes.\n",
    "- **Documentos irrelevantes en el contexto**: Indica que el m√©todo de `retrieval` debe ser mejorado (por ejemplo, pasando de b√∫squeda por palabras clave a b√∫squeda sem√°ntica con embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusi√≥n\n",
    "\n",
    "La evaluaci√≥n es un pilar fundamental en el desarrollo de sistemas de IA robustos. LangSmith nos ofrece un conjunto de herramientas poderosas para automatizar este proceso en sistemas RAG, permiti√©ndonos pasar de un desarrollo basado en la intuici√≥n a uno guiado por datos y m√©tricas objetivas. Con este enfoque, podemos mejorar de forma iterativa la calidad y fiabilidad de nuestras aplicaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
